# -*- coding: utf-8 -*-
"""
Outlook -> Azure OpenAI (genai-nexus) -> Draft reply (RUN ONCE) + Self-notification
Privacy-focused: redact sensitive info locally (regex + optional spaCy NER) BEFORE sending anything to Azure OpenAI.

Key properties
- Uses ONLY locally selected snippets for grounding (but filenames are NOT sent to the model)
- Removes personal/company/supplier/location identifiers via NER (if available) + regex
- Removes emails/phones/URLs/IDs/money amounts via regex
- Forces paraphrasing (no copy/paste from snippets)
- Creates Outlook reply draft
- Marks processed emails with category to avoid re-processing
- Sends you a self-notification containing which KB files were used (for traceability)

Run hourly via Windows Task Scheduler (recommended) -> run this file once per trigger.
"""

import os
import re
import time
from pathlib import Path
from typing import List, Tuple, Optional

import win32com.client as win32
from openai import AzureOpenAI
from docx import Document as DocxDocument
from pypdf import PdfReader
from dotenv import load_dotenv

load_dotenv()

# =========================
# EDIT THESE
# =========================
TARGET_MAILBOX = "shubham.tandon@mercedes-benz.com"   # must match Outlook store DisplayName (substring match)
WATCH_FOLDER_NAME = "Inbox"                           # "Inbox" or subfolder under Inbox

KB_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Test Data"

SUBJECT_TOKEN = "[bot]"        # set "" to disable subject gating
REQUIRE_UNREAD = True
AUTO_SEND = False              # Draft only
PROCESS_PER_RUN = 3
SCAN_LIMIT = 250
STARTUP_DELAY_SEC = 5

# Empty set = allow anyone
ALLOWED_SENDERS = set()        # e.g. {"a.b@company.com", "c.d@company.com"}

# Azure OpenAI (corporate)
AZURE_OPENAI_ENDPOINT = "https://genai-nexus.api.corpinter.net/apikey/"
AZURE_API_VERSION = "2024-06-01"
AZURE_DEPLOYMENT_NAME = "gpt-4o"   # DEPLOYMENT NAME in your org

# Self notification after draft created
SELF_NOTIFY = True
SELF_NOTIFY_TO = TARGET_MAILBOX
# =========================

# KB limits
MAX_FILES = 6
MAX_CHARS_PER_FILE = 4500
MAX_TOTAL_CHARS = 14000
SUPPORTED_EXTS = {".txt", ".docx", ".pdf"}

# Outlook category used to mark processed mails
PROCESSED_CATEGORY = "AI-Drafted"

# Special DOCX with table columns: Fragen (Q) and Antwort/ Erklärung (A)
SPECIAL_QA_DOC_NAME = "2025-11-06 Frageliste MBEAL - Nachhaltigkeit.docx"

# =========================
# Optional spaCy NER redaction
# =========================
USE_SPACY_NER = True  # if models aren't installed, script automatically falls back to regex-only

NLP_DE = None
NLP_EN = None

def _try_load_spacy_models():
    """Try loading spaCy models. If unavailable, return (None, None)."""
    if not USE_SPACY_NER:
        return None, None
    try:
        import spacy  # noqa
    except Exception:
        return None, None

    nlp_de = None
    nlp_en = None

    try_names_de = ["de_core_news_sm", "de_core_news_md"]
    try_names_en = ["en_core_web_sm", "en_core_web_md"]

    for name in try_names_de:
        try:
            import spacy
            nlp_de = spacy.load(name)
            break
        except Exception:
            pass

    for name in try_names_en:
        try:
            import spacy
            nlp_en = spacy.load(name)
            break
        except Exception:
            pass

    return nlp_de, nlp_en


NLP_DE, NLP_EN = _try_load_spacy_models()


def guess_language(text: str) -> str:
    """Light heuristic to pick DE vs EN NER; falls back to whichever model exists."""
    if NLP_DE and not NLP_EN:
        return "de"
    if NLP_EN and not NLP_DE:
        return "en"

    t = (text or "").lower()
    if any(ch in t for ch in "äöüß"):
        return "de"
    de_markers = [" und ", " der ", " die ", " das ", " nicht ", " mit ", " für ", " bitte ", " danke ", " sowie "]
    en_markers = [" and ", " the ", " not ", " with ", " please ", " thanks ", " also "]
    de_hits = sum(1 for w in de_markers if w in t)
    en_hits = sum(1 for w in en_markers if w in t)
    return "de" if de_hits >= en_hits else "en"


# =========================
# Redaction (privacy)
# =========================
def clean_ws(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()


# Terms you want removed locally even if NER misses them (keep short/minimal)
REDACT_TERMS = [
    "Mercedes-Benz", "Mercedes Benz", "Daimler", "corpinter",
]

# Regex patterns for sensitive formats
REDACT_PATTERNS = [
    # email addresses
    (r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b", ""),
    # URLs
    (r"\bhttps?://[^\s<>()]+\b", ""),
    (r"\bwww\.[^\s<>()]+\b", ""),
    # phone numbers (broad)
    (r"(?:(?:\+|00)\d{1,3}[\s\-]?)?(?:\(?\d{2,5}\)?[\s\-]?)?\d[\d\s\-]{6,}\d", ""),
    # IDs / references that include digits (reduces false positives)
    (r"\b(?:PO|PR|NCR|Ticket|Case|Req|Request|Material|Part|Supplier|Portal|Round|ID|Ref)\s*[:#]?\s*[A-Za-z0-9\-_/]*\d[A-Za-z0-9\-_/]*\b",
     "the relevant reference"),
    # money amounts
    (r"(?i)\b(?:EUR|USD|GBP|CHF)\s*\d[\d\.\,\s]*\b", "an amount"),
    (r"\b\d[\d\.\,\s]*\s*(?:€|EUR|USD|GBP|CHF)\b", "an amount"),
    (r"\b€\s*\d[\d\.\,\s]*\b", "an amount"),
]


def regex_redact(text: str) -> str:
    t = text or ""
    for term in REDACT_TERMS:
        if term:
            t = re.sub(re.escape(term), "", t, flags=re.IGNORECASE)
    for pat, repl in REDACT_PATTERNS:
        t = re.sub(pat, repl, t)
    return t


def ner_redact(text: str) -> str:
    """
    Remove PERSON/ORG/GPE/LOC etc (privacy). Removes entity substrings (no placeholders).
    If spaCy models not available, returns text unchanged.
    """
    if not text:
        return ""
    if not (NLP_DE or NLP_EN):
        return text

    lang = guess_language(text)
    nlp = NLP_DE if lang == "de" else NLP_EN
    if not nlp:
        nlp = NLP_EN or NLP_DE
    if not nlp:
        return text

    doc = nlp(text)

    # Labels to remove (privacy)
    redact_labels = {"PERSON", "ORG", "GPE", "LOC", "FAC", "PRODUCT", "EVENT", "NORP"}

    spans = [ent for ent in doc.ents if ent.label_ in redact_labels]
    if not spans:
        return text

    spans = sorted(spans, key=lambda s: (s.start_char, s.end_char), reverse=True)
    out = text
    for ent in spans:
        out = out[:ent.start_char] + " " + out[ent.end_char:]

    out = clean_ws(out)
    out = re.sub(r"\s+([,.;:])", r"\1", out)
    out = re.sub(r"\(\s*\)", "", out)
    return out.strip()


def redact_sensitive(text: str) -> str:
    """Regex first (formats), then NER (entities), then cleanup."""
    t = regex_redact(text or "")
    t = ner_redact(t)
    t = clean_ws(t)
    return t


def sanitize_for_llm(text: str) -> str:
    """Extra guard: strip any leftover bracket tokens or weird markers."""
    t = text or ""
    t = re.sub(r"\[REDACTED_[A-Z_]+\]", "", t)
    return clean_ws(t)


# =========================
# Azure OpenAI client
# =========================
def build_azure_client() -> AzureOpenAI:
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        raise SystemExit("OPENAI_API_KEY env var missing (corporate Azure key).")
    return AzureOpenAI(
        api_version=AZURE_API_VERSION,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=key,
    )


# =========================
# KB readers
# =========================
def read_txt(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="ignore")


def extract_docx_tables_as_text(doc: DocxDocument) -> str:
    out = []
    for table in doc.tables:
        for row in table.rows:
            cells = [clean_ws(c.text) for c in row.cells]
            if any(cells):
                out.append(" | ".join(cells))
    return "\n".join(out)


def find_col_index(headers: List[str], target: str) -> Optional[int]:
    target_norm = re.sub(r"\s+", "", target).lower()
    for i, h in enumerate(headers):
        hn = re.sub(r"\s+", "", (h or "")).lower()
        if hn == target_norm:
            return i
    return None


def read_special_qa_docx(p: Path) -> str:
    """
    For SPECIAL_QA_DOC_NAME:
      Column "Fragen" -> question
      Column "Antwort/ Erklärung" -> answer
    Outputs Q/A pairs.
    """
    doc = DocxDocument(str(p))
    qa_lines = []

    for table in doc.tables:
        if not table.rows:
            continue

        header_cells = [clean_ws(c.text) for c in table.rows[0].cells]
        if not any(header_cells):
            continue

        q_idx = find_col_index(header_cells, "Fragen")
        a_idx = (
            find_col_index(header_cells, "Antwort/ Erklärung")
            or find_col_index(header_cells, "Antwort/Erklärung")
            or find_col_index(header_cells, "Antwort")
            or find_col_index(header_cells, "Erklärung")
        )

        if q_idx is None or a_idx is None:
            continue

        for row in table.rows[1:]:
            cells = [clean_ws(c.text) for c in row.cells]
            if q_idx >= len(cells) or a_idx >= len(cells):
                continue
            q = clean_ws(cells[q_idx])
            a = clean_ws(cells[a_idx])
            if not q and not a:
                continue
            qa_lines.append(f"Q: {q}\nA: {a}")

    if not qa_lines:
        paras = "\n".join(clean_ws(par.text) for par in doc.paragraphs if clean_ws(par.text))
        tables = extract_docx_tables_as_text(doc)
        return clean_ws(paras + "\n" + tables)

    return "\n\n".join(qa_lines)


def read_docx(p: Path) -> str:
    if p.name.strip().lower() == SPECIAL_QA_DOC_NAME.strip().lower():
        return read_special_qa_docx(p)

    doc = DocxDocument(str(p))
    paras = "\n".join(clean_ws(par.text) for par in doc.paragraphs if clean_ws(par.text))
    tables = extract_docx_tables_as_text(doc)
    return clean_ws(paras + "\n" + tables)


def read_pdf(p: Path) -> str:
    out = []
    r = PdfReader(str(p))
    for pg in r.pages:
        try:
            out.append(pg.extract_text() or "")
        except Exception:
            pass
    return "\n".join(out)


def load_kb(dirpath: str) -> List[Tuple[str, str]]:
    base = Path(dirpath)
    if not base.exists() or not base.is_dir():
        raise SystemExit(f"KB_DIR not found or not a folder: {dirpath}")

    files = [p for p in base.rglob("*") if p.is_file() and p.suffix.lower() in SUPPORTED_EXTS]
    if not files:
        raise SystemExit(f"No .txt/.docx/.pdf found in: {dirpath}")

    out: List[Tuple[str, str]] = []
    for p in sorted(files):
        try:
            ext = p.suffix.lower()
            raw = read_txt(p) if ext == ".txt" else (read_docx(p) if ext == ".docx" else read_pdf(p))
            raw = clean_ws(raw)
            if raw:
                # Keep ORIGINAL for retrieval scoring; redact later before LLM call
                out.append((p.name, raw[:MAX_CHARS_PER_FILE]))
        except Exception as e:
            print("Skip KB file:", p.name, "-", e)

    if not out:
        raise SystemExit("Docs found, but no extractable text. Use text PDFs or .txt/.docx.")
    return out


# =========================
# Local retrieval (heuristic)
# =========================
def pick_relevant(files: List[Tuple[str, str]], subject: str, body_text: str) -> List[Tuple[str, str]]:
    q = (subject + " " + body_text).lower()
    scores = []
    for name, text in files:
        score = 0
        # filename tokens weighted
        for token in re.split(r"[^a-z0-9]+", Path(name).stem.lower()):
            if token and token in q:
                score += 6
        # content token overlap
        for token in set(re.split(r"[^a-z0-9]+", q)):
            if token and token in text.lower():
                score += 1
        scores.append((score, name, text))

    scores.sort(reverse=True)
    picked = [(n, t) for s, n, t in scores[:MAX_FILES]]

    total = 0
    cut: List[Tuple[str, str]] = []
    for n, t in picked:
        if total + len(t) > MAX_TOTAL_CHARS:
            cut.append((n, t[: max(0, MAX_TOTAL_CHARS - total)]))
            break
        cut.append((n, t))
        total += len(t)
    return cut


# =========================
# Prompt builder (NO filenames sent to model)
# =========================
def make_prompt(snips: List[Tuple[str, str]], subject: str, email_text: str) -> Tuple[str, List[str]]:
    """
    Returns:
      - prompt string (doc labels DOC1.. only)
      - list of real filenames used (for your self-notification)
    """
    red_subj = sanitize_for_llm(redact_sensitive(subject))
    red_body = sanitize_for_llm(redact_sensitive(email_text))

    real_files_used: List[str] = []
    snippet_blocks: List[str] = []

    for i, (fname, text) in enumerate(snips, start=1):
        label = f"DOC{i}"
        real_files_used.append(fname)
        red_txt = sanitize_for_llm(redact_sensitive(text))
        if red_txt:
            snippet_blocks.append(f"[{label}]\n{red_txt}")

    block = "\n\n---\n\n".join(snippet_blocks) if snippet_blocks else "(no snippets)"

    prompt = f"""You are an enterprise email assistant.

HARD CONSTRAINTS (must follow exactly):
- Use ONLY the SNIPPETS below as factual grounding.
- If the answer is not explicitly supported by the snippets, reply exactly:
"I don't have that information in the provided documents."
- Do NOT output personal data, company/supplier names, email addresses, phone numbers, IDs, or money amounts.
- Do NOT copy/paste from the snippets. Paraphrase. Do not reproduce more than 10 consecutive words from any snippet.
- Keep to max 140 words. Professional tone.

OUTPUT:
- Produce a ready-to-send email reply.

SNIPPETS:
{block}

EMAIL SUBJECT:
{red_subj}

EMAIL QUESTION (plain text):
{red_body}
"""
    return prompt, real_files_used


def call_azure_openai(client: AzureOpenAI, prompt: str) -> str:
    r = client.chat.completions.create(
        model=AZURE_DEPLOYMENT_NAME,
        temperature=0.1,
        messages=[
            {
                "role": "system",
                "content": (
                    "Follow constraints strictly. Answer only from snippets, paraphrase, "
                    "and never include any sensitive content."
                ),
            },
            {"role": "user", "content": prompt},
        ],
    )
    return r.choices[0].message.content or ""


# =========================
# Outlook helpers
# =========================
def clean_html_to_text(html: str) -> str:
    txt = re.sub(r"<[^>]+>", " ", html or "", flags=re.S)
    return clean_ws(txt)


def get_sender_smtp(mail) -> str:
    try:
        addr = (mail.SenderEmailAddress or "").lower()
        if addr.startswith("/o="):
            ex = mail.Sender.GetExchangeUser()
            if ex:
                return (ex.PrimarySmtpAddress or "").lower()
        return addr
    except Exception:
        return (mail.SenderEmailAddress or "").lower()


def add_processed_category(mail):
    try:
        cats = mail.Categories or ""
        if PROCESSED_CATEGORY.lower() not in cats.lower():
            mail.Categories = (cats + "," + PROCESSED_CATEGORY).strip(",")
            mail.Save()
    except Exception:
        pass


def get_target_folder():
    ns = win32.Dispatch("Outlook.Application").GetNamespace("MAPI")

    target_store = None
    for st in ns.Stores:
        if TARGET_MAILBOX.lower() in (st.DisplayName or "").lower():
            target_store = st
            break

    if not target_store:
        print("Available stores (use one of these in TARGET_MAILBOX):")
        for st in ns.Stores:
            print(" -", st.DisplayName)
        raise SystemExit("Target mailbox not found.")

    inbox = target_store.GetDefaultFolder(6)  # Inbox

    if WATCH_FOLDER_NAME.lower() == "inbox":
        return inbox, target_store.DisplayName, "Inbox"

    for f in inbox.Folders:
        if (f.Name or "").lower() == WATCH_FOLDER_NAME.lower():
            return f, target_store.DisplayName, f.Name

    raise SystemExit(f"Subfolder '{WATCH_FOLDER_NAME}' not found under Inbox of {target_store.DisplayName}")


# =========================
# Self notification
# =========================
def name_from_email(email: str) -> str:
    """
    First token before '.' from mailbox local part: firstname.lastname@ -> Firstname
    """
    email = (email or "").strip().lower()
    local = email.split("@")[0] if "@" in email else email
    first = local.split(".")[0] if local else ""
    return (first[:1].upper() + first[1:]) if first else "Colleague"


def get_account_for_mailbox(ns, mailbox_substring: str):
    try:
        for acc in ns.Session.Accounts:
            smtp = (getattr(acc, "SmtpAddress", "") or "").lower()
            if mailbox_substring.lower() in smtp or smtp in mailbox_substring.lower():
                return acc
    except Exception:
        pass
    return None


def send_self_notification(ns, from_mailbox: str, to_addr: str, orig_subject: str, requester_email: str, kb_files_used: List[str]):
    requester_name = name_from_email(requester_email)

    kb_html = "<br>".join([f"- {re.sub(r'&', '&amp;', f)}" for f in kb_files_used]) if kb_files_used else "(none)"

    msg = ns.Application.CreateItem(0)  # MailItem
    msg.To = to_addr
    msg.Subject = f"Draft created (review needed): {orig_subject}"
    msg.HTMLBody = (
        f"<p>A draft reply has been created in Outlook.</p>"
        f"<ul>"
        f"<li><b>Original subject:</b> {orig_subject}</li>"
        f"<li><b>Requester:</b> {requester_email}</li>"
        f"</ul>"
        f"<p>Please verify the draft and then send it to <b>{requester_name}</b>.</p>"
        f"<p><b>KB files used (internal trace):</b><br>{kb_html}</p>"
    )

    acc = get_account_for_mailbox(ns, from_mailbox)
    if acc:
        try:
            msg.SendUsingAccount = acc
        except Exception:
            pass

    msg.Send()


# =========================
# MAIN (RUN ONCE)
# =========================
def main():
    time.sleep(STARTUP_DELAY_SEC)

    if USE_SPACY_NER and not (NLP_DE or NLP_EN):
        print("WARNING: spaCy NER models not loaded. Using regex-only redaction.")
        print("If you want NER, install models in this Python env:")
        print("  python -m spacy download de_core_news_sm")
        print("  python -m spacy download en_core_web_sm")

    print("Loading KB from:", KB_DIR)
    kb_files = load_kb(KB_DIR)
    print("KB loaded:", len(kb_files), "documents")

    ns = win32.Dispatch("Outlook.Application").GetNamespace("MAPI")
    folder, store_name, folder_name = get_target_folder()
    print(f"Mailbox={store_name} | Folder={folder_name}")

    client = build_azure_client()
    allowed = {a.lower() for a in ALLOWED_SENDERS}

    items = folder.Items
    items.Sort("[ReceivedTime]", True)

    drafted = 0
    checked = 0

    for mail in items:
        checked += 1
        if checked > SCAN_LIMIT:
            break
        if drafted >= PROCESS_PER_RUN:
            break

        try:
            # Only MailItem
            if getattr(mail, "Class", None) != 43:
                continue

            # Skip already processed
            if PROCESSED_CATEGORY.lower() in (mail.Categories or "").lower():
                continue

            # Unread gate
            if REQUIRE_UNREAD and not mail.UnRead:
                continue

            sender = get_sender_smtp(mail)
            if allowed and sender not in allowed:
                continue

            subject = mail.Subject or ""
            if SUBJECT_TOKEN and SUBJECT_TOKEN.lower() not in subject.lower():
                continue

            body_text = clean_html_to_text(mail.HTMLBody or "")

            # Retrieve locally from original text (no redaction here)
            snips = pick_relevant(kb_files, subject, body_text)

            # Build prompt with redaction + DOC labels (no filenames sent)
            prompt, kb_files_used = make_prompt(snips, subject, body_text)

            # LLM call
            answer = call_azure_openai(client, prompt)

            # Post-sanitize output again (belt-and-suspenders)
            answer = sanitize_for_llm(redact_sensitive(answer))

            # Draft reply
            reply = mail.Reply()
            reply.HTMLBody = f"<p>{answer}</p><hr>" + reply.HTMLBody

            if AUTO_SEND:
                reply.Send()
                print("Sent:", subject)
            else:
                reply.Save()
                print("Draft created:", subject)

                if SELF_NOTIFY:
                    try:
                        send_self_notification(
                            ns=ns,
                            from_mailbox=TARGET_MAILBOX,
                            to_addr=SELF_NOTIFY_TO,
                            orig_subject=subject,
                            requester_email=sender,
                            kb_files_used=kb_files_used,
                        )
                        print("Self-notification sent for:", subject)
                    except Exception as e:
                        print("Self-notification error:", e)

            # Mark processed
            add_processed_category(mail)
            drafted += 1

        except Exception as e:
            print("Mail error:", getattr(mail, "Subject", "<no subject>"), "-", e)

    print(f"Done. Checked={checked}, Drafted={drafted}")


if __name__ == "__main__":
    main()
