# -*- coding: utf-8 -*-
"""
Outlook -> Azure OpenAI (genai-nexus) -> Draft reply (RUN ONCE) + Self notification
with spaCy NER redaction + "paraphrase, don't copy snippets" constraints.

What it does:
- Reads newest emails in your target mailbox/folder
- Gates by subject token [bot] (optional) + unread (optional) + allowed senders (optional)
- Loads local KB docs (.txt/.docx/.pdf) from OneDrive-synced folder
- Retrieves top relevant snippets (local heuristic)
- Redacts sensitive info LOCALLY (regex + spaCy NER) BEFORE sending to Azure OpenAI
- Calls Azure OpenAI with snippet-only constraints + paraphrase requirement
- Creates a REPLY draft in Outlook
- Marks original email with category "AI-Drafted" to prevent reprocessing
- Sends YOU a self-notification email after draft created, including KB file names used
"""

import os
import re
import time
from pathlib import Path
from typing import List, Tuple, Optional, Dict

import win32com.client as win32
from openai import AzureOpenAI
from docx import Document as DocxDocument
from pypdf import PdfReader
from dotenv import load_dotenv

# spaCy (Python 3.11/3.12 recommended)
import spacy

load_dotenv()

# =========================
# EDIT THESE
# =========================
TARGET_MAILBOX = "shubham.tandon@mercedes-benz.com"   # must match Outlook store DisplayName (substring match)
WATCH_FOLDER_NAME = "Inbox"                           # "Inbox" or subfolder under Inbox

KB_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Test Data"

SUBJECT_TOKEN = "[bot]"       # set "" to disable subject gating
REQUIRE_UNREAD = True
AUTO_SEND = False             # Draft only
PROCESS_PER_RUN = 3
SCAN_LIMIT = 200
STARTUP_DELAY_SEC = 5

ALLOWED_SENDERS = set()       # empty = allow anyone

# Azure OpenAI (corporate) settings
AZURE_OPENAI_ENDPOINT = "https://genai-nexus.api.corpinter.net/apikey/"
AZURE_API_VERSION = "2024-06-01"
AZURE_DEPLOYMENT_NAME = "gpt-4o"   # DEPLOYMENT NAME in your org

# Notify yourself after draft created
SELF_NOTIFY = True
SELF_NOTIFY_TO = TARGET_MAILBOX
# =========================

PROCESSED_CATEGORY = "AI-Drafted"
MAX_FILES = 6
MAX_CHARS_PER_FILE = 4500
MAX_TOTAL_CHARS = 14000
SUPPORTED_EXTS = {".txt", ".docx", ".pdf"}

SPECIAL_QA_DOC_NAME = "2025-11-06 Frageliste MBEAL - Nachhaltigkeit.docx"

# =========================
# spaCy model loading
# =========================
def load_spacy_models():
    """
    Use small models (fast). Do NOT require transformers.
    """
    nlp_de = None
    nlp_en = None
    # Try common installed names
    for name in ["de_core_news_sm", "de_core_news_md"]:
        try:
            nlp_de = spacy.load(name)
            break
        except Exception:
            pass
    for name in ["en_core_web_sm", "en_core_web_md"]:
        try:
            nlp_en = spacy.load(name)
            break
        except Exception:
            pass

    if not nlp_de and not nlp_en:
        raise RuntimeError(
            "No spaCy language model found. Install at least one of: "
            "de_core_news_sm / en_core_web_sm."
        )
    return nlp_de, nlp_en


NLP_DE, NLP_EN = load_spacy_models()


def guess_language(text: str) -> str:
    """
    Very light heuristic: decide DE vs EN for NER to reduce false positives.
    Falls back to whichever model exists.
    """
    t = (text or "").lower()
    if not t.strip():
        return "en" if NLP_EN else "de"

    # German indicators
    de_hits = 0
    if any(ch in t for ch in "äöüß"):
        de_hits += 2
    de_words = [" und ", " der ", " die ", " das ", " nicht ", " mit ", " für ", " bitte ", " danke ", " sowie "]
    en_words = [" and ", " the ", " not ", " with ", " please ", " thanks ", " also "]
    de_hits += sum(1 for w in de_words if w in t)
    en_hits = sum(1 for w in en_words if w in t)

    if NLP_DE and not NLP_EN:
        return "de"
    if NLP_EN and not NLP_DE:
        return "en"

    return "de" if de_hits >= en_hits else "en"


# =========================
# Redaction configuration
# =========================
# Regex redaction (fast, catches typical sensitive formats)
REDACT_PATTERNS = [
    # email
    (r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}\b", ""),

    # URLs
    (r"\bhttps?://[^\s<>()]+\b", ""),
    (r"\bwww\.[^\s<>()]+\b", ""),

    # phone numbers (broad)
    (r"(?:(?:\+|00)\d{1,3}[\s\-]?)?(?:\(?\d{2,5}\)?[\s\-]?)?\d[\d\s\-]{6,}\d", ""),

    # IDs / references that include digits
    (r"\b(?:PO|PR|NCR|Ticket|Case|Req|Request|Material|Part|Supplier|Portal|Round|ID)\s*[:#]?\s*[A-Za-z0-9\-_/]*\d[A-Za-z0-9\-_/]*\b",
     "the relevant reference"),

    # money amounts (currency)
    (r"(?i)\b(?:EUR|USD|GBP|CHF)\s*\d[\d\.\,\s]*\b", "an amount"),
    (r"\b\d[\d\.\,\s]*\s*(?:€|EUR|USD|GBP|CHF)\b", "an amount"),
    (r"\b€\s*\d[\d\.\,\s]*\b", "an amount"),
]

# If you want to additionally remove some known internal terms locally (not sent to model),
# add them here. (Keep this minimal; spaCy ORG often already catches these.)
REDACT_TERMS = [
    "Mercedes-Benz", "Mercedes Benz", "Daimler", "corpinter",
]


def clean_ws(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()


def regex_redact(text: str) -> str:
    t = text or ""
    for term in REDACT_TERMS:
        if term:
            t = re.sub(re.escape(term), "", t, flags=re.IGNORECASE)
    for pat, repl in REDACT_PATTERNS:
        t = re.sub(pat, repl, t)
    return t


def ner_redact(text: str) -> str:
    """
    Remove PERSON/ORG/GPE/LOC and other identifying entities.
    We remove the entity text entirely (not placeholders), then cleanup.
    """
    if not text:
        return ""

    lang = guess_language(text)
    nlp = NLP_DE if lang == "de" else NLP_EN
    if not nlp:
        # fallback: whichever exists
        nlp = NLP_EN or NLP_DE

    doc = nlp(text)

    # Which labels to remove:
    # PERSON/ORG: names & orgs (supplier, company, person)
    # GPE/LOC/FAC: location-like
    # PRODUCT/EVENT: sometimes internal product / event names
    # NORP: nationalities/political/religious groups (optional for privacy)
    redact_labels = {"PERSON", "ORG", "GPE", "LOC", "FAC", "PRODUCT", "EVENT", "NORP"}

    spans = [ent for ent in doc.ents if ent.label_ in redact_labels]
    if not spans:
        return text

    # Remove spans from end to start to preserve indices
    spans = sorted(spans, key=lambda s: (s.start_char, s.end_char), reverse=True)
    out = text
    for ent in spans:
        # Remove the exact substring
        out = out[:ent.start_char] + " " + out[ent.end_char:]

    # Cleanup
    out = clean_ws(out)
    out = re.sub(r"\s+([,.;:])", r"\1", out)
    out = re.sub(r"\(\s*\)", "", out)
    return out.strip()


def redact_sensitive(text: str) -> str:
    """
    Full redaction pipeline: regex first (formats), then NER (entities), then final cleanup.
    """
    t = regex_redact(text or "")
    t = ner_redact(t)
    # final cleanup
    t = clean_ws(t)
    return t


def sanitize_for_llm(text: str) -> str:
    """
    Extra guard: remove any leftover bracket tokens if present.
    """
    t = text or ""
    t = re.sub(r"\[REDACTED_[A-Z_]+\]", "", t)
    return clean_ws(t)


# =========================
# Azure OpenAI client
# =========================
def build_azure_client() -> AzureOpenAI:
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        raise SystemExit("OPENAI_API_KEY env var missing (corporate Azure key).")
    return AzureOpenAI(
        api_version=AZURE_API_VERSION,
        azure_endpoint=AZURE_OPENAI_ENDPOINT,
        api_key=key,
    )


# =========================
# KB readers
# =========================
def read_txt(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="ignore")


def extract_docx_tables_as_text(doc: DocxDocument) -> str:
    out = []
    for table in doc.tables:
        for row in table.rows:
            cells = [clean_ws(c.text) for c in row.cells]
            if any(cells):
                out.append(" | ".join(cells))
    return "\n".join(out)


def find_col_index(headers: List[str], target: str) -> Optional[int]:
    target_norm = re.sub(r"\s+", "", target).lower()
    for i, h in enumerate(headers):
        hn = re.sub(r"\s+", "", (h or "")).lower()
        if hn == target_norm:
            return i
    return None


def read_special_qa_docx(p: Path) -> str:
    """
    For SPECIAL_QA_DOC_NAME:
    Column "Fragen" -> Q
    Column "Antwort/ Erklärung" (and variants) -> A
    Output: Q/A pairs
    """
    doc = DocxDocument(str(p))
    qa_lines = []

    for table in doc.tables:
        if not table.rows:
            continue

        header_cells = [clean_ws(c.text) for c in table.rows[0].cells]
        if not any(header_cells):
            continue

        q_idx = find_col_index(header_cells, "Fragen")
        a_idx = (
            find_col_index(header_cells, "Antwort/ Erklärung")
            or find_col_index(header_cells, "Antwort/Erklärung")
            or find_col_index(header_cells, "Antwort")
            or find_col_index(header_cells, "Erklärung")
        )

        if q_idx is None or a_idx is None:
            continue

        for row in table.rows[1:]:
            cells = [clean_ws(c.text) for c in row.cells]
            if q_idx >= len(cells) or a_idx >= len(cells):
                continue
            q = clean_ws(cells[q_idx])
            a = clean_ws(cells[a_idx])
            if not q and not a:
                continue
            if q and a:
                qa_lines.append(f"Q: {q}\nA: {a}")
            elif q and not a:
                qa_lines.append(f"Q: {q}\nA: (no answer provided)")
            elif a and not q:
                qa_lines.append(f"Q: (missing question)\nA: {a}")

    if not qa_lines:
        paras = "\n".join(clean_ws(par.text) for par in doc.paragraphs if clean_ws(par.text))
        tables = extract_docx_tables_as_text(doc)
        return clean_ws(paras + "\n" + tables)

    return "\n\n".join(qa_lines)


def read_docx(p: Path) -> str:
    if p.name.strip().lower() == SPECIAL_QA_DOC_NAME.strip().lower():
        return read_special_qa_docx(p)

    doc = DocxDocument(str(p))
    paras = "\n".join(clean_ws(par.text) for par in doc.paragraphs if clean_ws(par.text))
    tables = extract_docx_tables_as_text(doc)
    return clean_ws(paras + "\n" + tables)


def read_pdf(p: Path) -> str:
    out = []
    r = PdfReader(str(p))
    for pg in r.pages:
        try:
            out.append(pg.extract_text() or "")
        except Exception:
            pass
    return "\n".join(out)


def load_kb(dirpath: str) -> List[Tuple[str, str]]:
    base = Path(dirpath)
    if not base.exists() or not base.is_dir():
        raise SystemExit(f"KB_DIR not found or not a folder: {dirpath}")

    files = [p for p in base.rglob("*") if p.is_file() and p.suffix.lower() in SUPPORTED_EXTS]
    if not files:
        raise SystemExit(f"No .txt/.docx/.pdf found in: {dirpath}")

    out: List[Tuple[str, str]] = []
    for p in sorted(files):
        try:
            ext = p.suffix.lower()
            raw = read_txt(p) if ext == ".txt" else (read_docx(p) if ext == ".docx" else read_pdf(p))
            raw = clean_ws(raw)
            if raw:
                # Do NOT redact at load-time; keep original for retrieval scoring.
                out.append((p.name, raw[:MAX_CHARS_PER_FILE]))
        except Exception as e:
            print("Skip KB file:", p.name, "-", e)

    if not out:
        raise SystemExit("Docs found, but no extractable text. Use text PDFs or .txt/.docx.")
    return out


# =========================
# Simple retrieval (local heuristic)
# =========================
def pick_relevant(files: List[Tuple[str, str]], subject: str, body_text: str) -> List[Tuple[str, str]]:
    q = (subject + " " + body_text).lower()
    scores = []
    for name, text in files:
        score = 0
        for token in re.split(r"[^a-z0-9]+", Path(name).stem.lower()):
            if token and token in q:
                score += 6
        for token in set(re.split(r"[^a-z0-9]+", q)):
            if token and token in text.lower():
                score += 1
        scores.append((score, name, text))

    scores.sort(reverse=True)
    picked = [(n, t) for s, n, t in scores[:MAX_FILES]]

    total = 0
    cut: List[Tuple[str, str]] = []
    for n, t in picked:
        if total + len(t) > MAX_TOTAL_CHARS:
            cut.append((n, t[: max(0, MAX_TOTAL_CHARS - total)]))
            break
        cut.append((n, t))
        total += len(t)
    return cut


# =========================
# Prompt builder (NO filenames sent to model)
# =========================
def make_prompt(snips: List[Tuple[str, str]], subject: str, email_text: str) -> Tuple[str, List[str]]:
    """
    Returns:
      - prompt string (doc labels DOC1.. only)
      - list of real filenames used (for your self-notification)
    """
    # Redact input
    red_subj = sanitize_for_llm(redact_sensitive(subject))
    red_body = sanitize_for_llm(redact_sensitive(email_text))

    # Redact snippets and replace filenames with DOC# labels
    real_files_used: List[str] = []
    snippet_blocks: List[str] = []

    for i, (fname, text) in enumerate(snips, start=1):
        label = f"DOC{i}"
        real_files_used.append(fname)
        red_txt = sanitize_for_llm(redact_sensitive(text))
        if red_txt:
            snippet_blocks.append(f"[{label}]\n{red_txt}")

    block = "\n\n---\n\n".join(snippet_blocks) if snippet_blocks else "(no snippets)"

    prompt = f"""You are an enterprise email assistant.

HARD CONSTRAINTS:
- Use ONLY the SNIPPETS below as factual grounding.
- If the answer is not explicitly supported by the snippets, reply exactly:
"I don't have that information in the provided documents."
- Do NOT output personal data, company/supplier names, email addresses, phone numbers, IDs, or money amounts.
- Do NOT copy/paste from the snippets. Paraphrase. Do not reproduce more than 10 consecutive words from any snippet.
- Keep to max 140 words. Professional tone.

OUTPUT:
- Produce a ready-to-send email reply.

SNIPPETS:
{block}

EMAIL SUBJECT:
{red_subj}

EMAIL QUESTION (plain text):
{red_body}
"""
    return prompt, real_files_used


def call_azure_openai(client: AzureOpenAI, prompt: str) -> str:
    r = client.chat.completions.create(
        model=AZURE_DEPLOYMENT_NAME,
        temperature=0.1,
        messages=[
            {
                "role": "system",
                "content": (
                    "You must follow constraints strictly. "
                    "Answer only from snippets, paraphrase, and avoid any sensitive content."
                ),
            },
            {"role": "user", "content": prompt},
        ],
    )
    return r.choices[0].message.content or ""


# =========================
# Outlook helpers
# =========================
def clean_html_to_text(html: str) -> str:
    txt = re.sub(r"<[^>]+>", " ", html or "", flags=re.S)
    return clean_ws(txt)


def get_sender_smtp(mail) -> str:
    try:
        addr = (mail.SenderEmailAddress or "").lower()
        if addr.startswith("/o="):
            ex = mail.Sender.GetExchangeUser()
            if ex:
                return (ex.PrimarySmtpAddress or "").lower()
        return addr
    except Exception:
        return (mail.SenderEmailAddress or "").lower()


def add_processed_category(mail):
    try:
        cats = mail.Categories or ""
        if PROCESSED_CATEGORY.lower() not in cats.lower():
            mail.Categories = (cats + "," + PROCESSED_CATEGORY).strip(",")
            mail.Save()
    except Exception:
        pass


def get_target_folder():
    ns = win32.Dispatch("Outlook.Application").GetNamespace("MAPI")

    target_store = None
    for st in ns.Stores:
        if TARGET_MAILBOX.lower() in (st.DisplayName or "").lower():
            target_store = st
            break

    if not target_store:
        print("Available stores (use one of these in TARGET_MAILBOX):")
        for st in ns.Stores:
            print(" -", st.DisplayName)
        raise SystemExit("Target mailbox not found.")

    inbox = target_store.GetDefaultFolder(6)  # Inbox

    if WATCH_FOLDER_NAME.lower() == "inbox":
        return inbox, target_store.DisplayName, "Inbox"

    for f in inbox.Folders:
        if (f.Name or "").lower() == WATCH_FOLDER_NAME.lower():
            return f, target_store.DisplayName, f.Name

    raise SystemExit(f"Subfolder '{WATCH_FOLDER_NAME}' not found under Inbox of {target_store.DisplayName}")


# =========================
# Self notification
# =========================
def name_from_email(email: str) -> str:
    email = (email or "").strip().lower()
    local = email.split("@")[0] if "@" in email else email
    first = local.split(".")[0] if local else ""
    return (first[:1].upper() + first[1:]) if first else "Colleague"


def get_account_for_mailbox(ns, mailbox_substring: str):
    try:
        for acc in ns.Session.Accounts:
            smtp = (getattr(acc, "SmtpAddress", "") or "").lower()
            if mailbox_substring.lower() in smtp or smtp in mailbox_substring.lower():
                return acc
    except Exception:
        pass
    return None


def send_self_notification(ns, from_mailbox: str, to_addr: str, orig_subject: str, requester_email: str, kb_files_used: List[str]):
    requester_name = name_from_email(requester_email)

    # Keep this internal email informative (it can contain filenames, but it's to YOU).
    kb_html = "<br>".join([f"- {re.sub(r'&', '&amp;', f)}" for f in kb_files_used]) if kb_files_used else "(none)"

    msg = ns.Application.CreateItem(0)  # MailItem
    msg.To = to_addr
    msg.Subject = f"Draft created (review needed): {orig_subject}"
    msg.HTMLBody = (
        f"<p>A draft reply has been created in Outlook.</p>"
        f"<ul>"
        f"<li><b>Original subject:</b> {orig_subject}</li>"
        f"<li><b>Requester:</b> {requester_email}</li>"
        f"</ul>"
        f"<p>Please verify the draft and then send it to <b>{requester_name}</b>.</p>"
        f"<p><b>KB files used (internal trace):</b><br>{kb_html}</p>"
    )

    acc = get_account_for_mailbox(ns, from_mailbox)
    if acc:
        try:
            msg.SendUsingAccount = acc
        except Exception:
            pass

    msg.Send()


# =========================
# MAIN (RUN ONCE)
# =========================
def main():
    time.sleep(STARTUP_DELAY_SEC)

    print("Loading KB from:", KB_DIR)
    kb_files = load_kb(KB_DIR)
    print("KB loaded:", len(kb_files), "documents")

    ns = win32.Dispatch("Outlook.Application").GetNamespace("MAPI")
    folder, store_name, folder_name = get_target_folder()
    print(f"Mailbox={store_name} | Folder={folder_name}")

    client = build_azure_client()
    allowed = {a.lower() for a in ALLOWED_SENDERS}

    items = folder.Items
    items.Sort("[ReceivedTime]", True)

    drafted = 0
    checked = 0

    for mail in items:
        checked += 1
        if checked > SCAN_LIMIT:
            break
        if drafted >= PROCESS_PER_RUN:
            break

        try:
            if getattr(mail, "Class", None) != 43:
                continue

            if PROCESSED_CATEGORY.lower() in (mail.Categories or "").lower():
                continue

            if REQUIRE_UNREAD and not mail.UnRead:
                continue

            sender = get_sender_smtp(mail)
            if allowed and sender not in allowed:
                continue

            subject = mail.Subject or ""
            if SUBJECT_TOKEN and SUBJECT_TOKEN.lower() not in subject.lower():
                continue

            body_text = clean_html_to_text(mail.HTMLBody or "")

            # Retrieve locally using original text
            snips = pick_relevant(kb_files, subject, body_text)

            prompt, kb_files_used = make_prompt(snips, subject, body_text)
            answer = call_azure_openai(client, prompt)

            # Post-sanitize output again (belt-and-suspenders)
            answer = sanitize_for_llm(redact_sensitive(answer))

            reply = mail.Reply()
            reply.HTMLBody = f"<p>{answer}</p><hr>" + reply.HTMLBody

            if AUTO_SEND:
                reply.Send()
                print("Sent:", subject)
            else:
                reply.Save()
                print("Draft created:", subject)

                if SELF_NOTIFY:
                    try:
                        send_self_notification(
                            ns=ns,
                            from_mailbox=TARGET_MAILBOX,
                            to_addr=SELF_NOTIFY_TO,
                            orig_subject=subject,
                            requester_email=sender,
                            kb_files_used=kb_files_used,
                        )
                        print("Self-notification sent for:", subject)
                    except Exception as e:
                        print("Self-notification error:", e)

            add_processed_category(mail)
            drafted += 1

        except Exception as e:
            print("Mail error:", getattr(mail, "Subject", "<no subject>"), "-", e)

    print(f"Done. Checked={checked}, Drafted={drafted}")


if __name__ == "__main__":
    main()
