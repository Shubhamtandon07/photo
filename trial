# -*- coding: utf-8 -*-
"""
OUTLOOK DRAFT BOT (NO LLM) — Notebook-safe (Python 3.14+)

Improvements included:
- Cached KB line index: read all docs once -> compare candidates across all docs/lines.
- Cross-lingual retrieval: EN question -> DE query expansion (small deterministic dictionary).
- Intent constraints:
  - "which standard?" -> answer must contain ISO/DIN/MBN/MBN/IEC/EN/SAE/VDA/etc.
  - "definition" -> answer must match explicit definition patterns if possible.
- Strong de-prioritization for mail-like docs: AW_/RE_/FW_/WG_.
- Redaction removes PII ONLY from extracted bullets/definition, not greeting/signature.

Run in Jupyter:
1) (Optional) build index once:
   build_or_load_kb_index(force_rebuild=True)
2) Run bot:
   run_bot_once()
"""

from __future__ import annotations

import re
import pickle
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
from html import escape

import win32com.client as win32


# =========================================================
# SETTINGS — EDIT THESE
# =========================================================
TARGET_MAILBOX = "shubham.tandon@mercedes-benz.com"
WATCH_FOLDER_NAME = "Inbox"  # Inbox or subfolder under Inbox

KB_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Test Data"

REQUIRE_UNREAD = True
PROCESS_PER_RUN = 3
SCAN_LIMIT = 250
STARTUP_DELAY_SEC = 1

REQUIRE_STRICT_SUBJECT = True  # subject must be exactly "bot"
PROCESSED_CATEGORY = "Drafted-NoLLM"

SELF_NOTIFY = True
SELF_NOTIFY_TO = TARGET_MAILBOX
CREATE_REMINDER_TASK = True
REMINDER_DAYS = 2

SUPPORTED_EXTS = {".txt", ".docx", ".pdf", ".xlsx"}

# Cache folder for index
CACHE_DIR = Path(KB_DIR) / "_cache"
CACHE_DIR.mkdir(parents=True, exist_ok=True)
KB_INDEX_PATH = CACHE_DIR / "kb_index.pkl"

# Limits
MAX_CHARS_PER_DOC = 200000  # avoid massive docs
MAX_LINES_PER_DOC = 6000    # guardrail for line explosion

# De-prioritize mail-like docs
MAILY_PREFIXES = ("aw_", "re_", "fw_", "wg_")
MAILY_HINTS = ["subject", "mail", "email", ".msg", "inbox", "outlook", "conversation"]

# Extra names to delete (remove, do not replace)
EXTRA_NAMES_TO_DELETE = [
    "lisa", "dario", "tim", "daniel", "rasmus", "marvin", "victoria", "janina",
    "veronika", "athanasia", "alina", "anne"
]


# =========================================================
# REDACTION (remove sensitive tokens; do NOT insert [PERSON])
# =========================================================
EMAIL_RE = re.compile(r"\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b", re.I)
PHONE_RE = re.compile(r"(?:(?:\+|00)\d{1,3}[\s\-]?)?(?:\(?\d{2,5}\)?[\s\-]?)?\d[\d\s\-]{6,}\d")
URL_RE = re.compile(r"\bhttps?://[^\s<>()]+\b", re.I)
DOMAIN_RE = re.compile(r"\b(?:[a-z0-9-]+\.)+(?:com|net|org|de|eu|io|gov|edu|co)\b", re.I)
IBAN_RE = re.compile(r"\b[A-Z]{2}\d{2}[A-Z0-9]{11,30}\b", re.I)
HEADER_LINE_RE = re.compile(r"(?im)^\s*(von|from|an|to|cc|bcc|gesendet|sent|betreff|subject)\s*:\s*.*$", re.M)

TITLE_NAME_RE = re.compile(r"\b(?:Mr|Mrs|Ms|Miss|Dr|Prof|Herr|Frau)\.?\s+[A-ZÄÖÜ][a-zäöüß]+(?:\s+[A-ZÄÖÜ][a-zäöüß]+){0,2}\b")
FIRST_LAST_RE = re.compile(r"\b[A-ZÄÖÜ][a-zäöüß]{2,}\s+[A-ZÄÖÜ][a-zäöüß]{2,}\b")


def clean_ws(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "")).strip()


def _remove_names_case_insensitive(text: str, names: list[str]) -> str:
    out = text
    for n in names:
        if not n:
            continue
        out = re.sub(rf"\b{re.escape(n)}\b", "", out, flags=re.I)
    return out


def redact_sensitive_remove(text: str) -> str:
    if not text:
        return ""
    t = text
    t = HEADER_LINE_RE.sub("", t)
    t = EMAIL_RE.sub("", t)
    t = PHONE_RE.sub("", t)
    t = URL_RE.sub("", t)
    t = DOMAIN_RE.sub("", t)
    t = IBAN_RE.sub("", t)

    t = TITLE_NAME_RE.sub("", t)
    t = FIRST_LAST_RE.sub("", t)
    t = _remove_names_case_insensitive(t, EXTRA_NAMES_TO_DELETE)

    # cleanup
    t = re.sub(r"[ \t]{2,}", " ", t)
    t = re.sub(r"\n{3,}", "\n\n", t)
    t = re.sub(r"\s+,", ",", t)
    t = re.sub(r"\(\s*\)", "", t)
    t = re.sub(r"\s+\.", ".", t)
    t = re.sub(r"\s+\)", ")", t)
    t = re.sub(r"\(\s+", "(", t)
    return t.strip()


# =========================================================
# OUTLOOK formatting
# =========================================================
def strict_subject_is_bot(subject: str) -> bool:
    return (subject or "").strip().lower() == "bot"


def safe_firstname_from_email(email: str) -> str:
    email = (email or "").strip()
    local = email.split("@", 1)[0] if "@" in email else email
    first = local.split(".", 1)[0].strip()
    if not first:
        return "Colleague"
    return first[:1].upper() + first[1:]


def clean_html_to_text(html: str) -> str:
    txt = re.sub(r"<[^>]+>", " ", html or "", flags=re.S)
    return clean_ws(txt)


def format_outlook_html(text: str) -> str:
    text = (text or "").replace("\r\n", "\n").strip()
    if not text:
        return "<p></p>"

    blocks = re.split(r"\n\s*\n", text)
    html_parts = []
    for block in blocks:
        lines = [ln.strip() for ln in block.split("\n") if ln.strip()]
        if not lines:
            continue
        if all(ln.startswith("- ") for ln in lines):
            html_parts.append("<ul>")
            for ln in lines:
                html_parts.append(f"<li>{escape(ln[2:].strip())}</li>")
            html_parts.append("</ul>")
        else:
            para = "<br>".join(escape(ln) for ln in lines)
            html_parts.append(f"<p>{para}</p>")
    return "\n".join(html_parts)


# =========================================================
# KB READERS
# =========================================================
def read_txt(p: Path) -> str:
    return p.read_text(encoding="utf-8", errors="ignore")


def read_docx(p: Path) -> str:
    try:
        from docx import Document as DocxDocument  # type: ignore
    except Exception:
        return ""
    doc = DocxDocument(str(p))
    out = []

    # paragraphs
    for par in doc.paragraphs:
        t = par.text.strip()
        if t:
            out.append(t)

    # tables (serialize)
    for table in doc.tables:
        for row in table.rows:
            cells = [c.text.strip() for c in row.cells]
            if any(cells):
                out.append(" | ".join(cells))

    return "\n".join(out).strip()


def read_pdf(p: Path) -> str:
    try:
        import pdfplumber  # type: ignore
        out = []
        with pdfplumber.open(str(p)) as pdf:
            for page in pdf.pages:
                out.append(page.extract_text() or "")
        return "\n".join(out).strip()
    except Exception:
        pass
    try:
        from pypdf import PdfReader  # type: ignore
        r = PdfReader(str(p))
        out = []
        for pg in r.pages:
            try:
                out.append(pg.extract_text() or "")
            except Exception:
                pass
        return "\n".join(out).strip()
    except Exception:
        return ""


def read_xlsx(p: Path) -> str:
    try:
        import openpyxl  # type: ignore
    except Exception:
        return ""
    wb = openpyxl.load_workbook(str(p), data_only=True, read_only=True)
    out = []
    for ws in wb.worksheets:
        out.append(f"Sheet: {ws.title}")
        max_rows = min(ws.max_row or 0, 200)
        max_cols = min(ws.max_column or 0, 30)
        for r in range(1, max_rows + 1):
            row_vals = []
            for c in range(1, max_cols + 1):
                v = ws.cell(row=r, column=c).value
                row_vals.append("" if v is None else str(v))
            if any(cell.strip() for cell in row_vals):
                out.append(" | ".join(clean_ws(x) for x in row_vals))
    return "\n".join(out).strip()


def extract_text_from_file(p: Path) -> str:
    ext = p.suffix.lower()
    if ext == ".txt":
        return read_txt(p)
    if ext == ".docx":
        return read_docx(p)
    if ext == ".pdf":
        return read_pdf(p)
    if ext == ".xlsx":
        return read_xlsx(p)
    return ""


def is_maily_filename(p: Path) -> bool:
    name = p.name.lower()
    stem = p.stem.lower()
    if stem.startswith("~$"):
        return True
    if stem.startswith(MAILY_PREFIXES):
        return True
    if any(h in name for h in MAILY_HINTS):
        return True
    return False


def load_kb_docs(dirpath: str) -> list[tuple[str, str, str]]:
    base = Path(dirpath)
    if not base.exists() or not base.is_dir():
        raise SystemExit(f"KB_DIR not found or not a folder: {dirpath}")

    files = [p for p in base.rglob("*") if p.is_file() and p.suffix.lower() in SUPPORTED_EXTS]
    docs = []
    for p in sorted(files):
        try:
            txt = extract_text_from_file(p)
            txt = (txt or "").strip()
            if not txt:
                continue
            txt = txt[:MAX_CHARS_PER_DOC]
            docs.append((str(p), p.name, txt))
        except Exception:
            continue
    return docs


# =========================================================
# TOKENIZATION + CROSS-LINGUAL EXPANSION
# =========================================================
STOPWORDS = set("""
the a an and or to of in on for with without from by at is are was were be been being
der die das und oder zu von im in am an auf für mit ohne aus bei ist sind war waren
""".split())


def tokenize(s: str) -> list[str]:
    toks = re.split(r"[^a-zA-Z0-9ÄÖÜäöüß]+", (s or "").lower())
    return [t for t in toks if t and t not in STOPWORDS and len(t) >= 2]


# Minimal EN->DE mapping for retrieval (not translation; just query expansion)
EN2DE = {
    "standard": ["standard", "norm", "mbn", "din", "iso", "iec", "en", "vda", "sae"],
    "standards": ["standard", "norm", "mbn", "din", "iso", "iec", "en", "vda", "sae"],
    "which": ["welche", "welcher", "welches"],
    "according": ["gemäß", "nach", "entsprechend"],
    "in": ["in", "im"],
    "accordance": ["gemäß", "nach", "entsprechend", "übereinstimmung"],
    "document": ["dokument", "unterlage", "nachweis"],
    "documentation": ["dokumentation", "dokumentieren", "nachweis"],
    "recycled": ["recyc", "rezykl", "recycling"],
    "proportion": ["anteil", "quote"],
    "evidence": ["nachweis", "beleg"],
    "requirement": ["anforderung", "erforderlich", "muss", "soll"],
    "required": ["erforderlich", "muss", "soll"],
    "shall": ["soll", "muss"],
    "must": ["muss", "erforderlich"],
    "where": ["wo", "wobei", "in welchem"],
    "how": ["wie"],
    "definition": ["definition", "begriff", "abkürzung", "steht für", "bedeutet"],
    "means": ["bedeutet", "steht für"],
}


def expand_query_tokens(question: str) -> set[str]:
    """
    For EN questions, add DE-ish tokens to improve retrieval against German docs.
    Also keep acronyms as anchors.
    """
    base = tokenize(question)
    out = set(base)

    # add expansions
    for tk in base:
        if tk in EN2DE:
            for x in EN2DE[tk]:
                out.add(x.lower())

    # keep acronyms (PPA, MBN, etc.)
    for m in re.findall(r"\b[A-Z]{2,10}\b", question or ""):
        out.add(m.lower())

    return out


# =========================================================
# INTENT DETECTION
# =========================================================
DEF_PATTERNS = [
    re.compile(r"(?i)\bwhat\s+is\s+([A-Za-z][A-Za-z0-9\-\s_/]{1,50})\??\b"),
    re.compile(r"(?i)\bwhat\s+does\s+([A-Za-z][A-Za-z0-9\-\s_/]{1,50})\s+mean\??\b"),
    re.compile(r"(?i)\bwas\s+ist\s+([A-Za-zÄÖÜäöüß][A-Za-zÄÖÜäöüß0-9\-\s_/]{1,50})\??\b"),
    re.compile(r"(?i)\bwas\s+bedeutet\s+([A-Za-zÄÖÜäöüß][A-Za-zÄÖÜäöüß0-9\-\s_/]{1,50})\??\b"),
]

WHICH_STANDARD_PATTERNS = [
    re.compile(r"(?i)\bwhich\s+standard(s)?\b"),
    re.compile(r"(?i)\bwhich\s+norm(s)?\b"),
    re.compile(r"(?i)\bin\s+accordance\s+with\s+which\b"),
    re.compile(r"(?i)\bgemäß\s+welch"),
    re.compile(r"(?i)\bnach\s+welch"),
]

REQ_HINTS = [
    "must", "shall", "required", "requirement", "how", "where", "which document", "evidence", "proof",
    "muss", "soll", "erforder", "anforder", "wie", "wo", "welches dokument", "nachweis", "beleg"
]


def detect_intent(question: str) -> str:
    q = clean_ws(question).lower()
    if any(p.search(q) for p in DEF_PATTERNS):
        return "definition"
    if any(p.search(q) for p in WHICH_STANDARD_PATTERNS):
        return "which_standard"
    if any(h in q for h in REQ_HINTS):
        return "requirement"
    return "general"


def extract_focus_term(question: str) -> str | None:
    q = clean_ws(question)
    for pat in DEF_PATTERNS:
        m = pat.search(q)
        if m:
            term = clean_ws(m.group(1))
            m2 = re.search(r"\b([A-Z]{2,10})\b", term)
            return m2.group(1) if m2 else term
    # fallback acronym
    m = re.search(r"\b([A-Z]{2,10})\b", q)
    return m.group(1) if m else None


# =========================================================
# DOC PRIORITY
# =========================================================
def doc_priority_adjustment(filename: str) -> float:
    name = (filename or "").lower()
    adj = 0.0

    if name.startswith(MAILY_PREFIXES):
        adj -= 0.35  # strong penalty
    if is_maily_filename(Path(filename)):
        adj -= 0.15

    # boost likely authoritative docs
    boosts = ["standard", "norm", "mbn", "iso", "din", "guideline", "handbook", "kapitel", "chapter", "requirements", "requirement", "glossary", "definition", "begriffe", "abkürz"]
    if any(b in name for b in boosts):
        adj += 0.10
    return adj


# =========================================================
# INDEX STRUCTURE
# =========================================================
STD_TOKEN_RE = re.compile(r"(?i)\b(ISO\s*\d+|DIN\s*\w+\d+|EN\s*\d+|IEC\s*\d+|SAE\s*\w+\d+|VDA\s*\d+|MBN\s*\d+|MBN\s*\w+)\b")
STD_CONTEXT_RE = re.compile(r"(?i)\b(in\s+accordance\s+with|according\s+to|gemäß|nach|entsprechend)\b")

DEF_CONTEXT_RE = re.compile(r"(?i)\b(stands\s+for|steht\s+für|means|bedeutet|refers\s+to|=)\b")
REQ_CONTEXT_RE = re.compile(r"(?i)\b(must|shall|required|requirement|muss|soll|erforder|anforder|nachweis|beleg)\b")


@dataclass
class KBLine:
    doc: str
    fullpath: str
    text: str
    tokens: frozenset[str]
    has_std: bool
    has_std_context: bool
    has_def_context: bool
    has_req_context: bool


def split_to_lines(text: str) -> list[str]:
    """
    Conservative splitting:
    - keep bullet lines
    - also split long paragraphs into sentences
    """
    text = text or ""
    raw_lines = [ln.strip() for ln in text.splitlines()]
    raw_lines = [ln for ln in raw_lines if ln]

    out = []
    for ln in raw_lines:
        # If it's short, keep it
        if len(ln) <= 220:
            out.append(ln)
            continue
        # Otherwise split into sentences
        parts = re.split(r"(?<=[\.\!\?])\s+", ln)
        for p in parts:
            p = p.strip()
            if p and len(p) >= 25:
                out.append(p)
    return out


def build_kb_index(kb_docs: list[tuple[str, str, str]]) -> list[KBLine]:
    idx: list[KBLine] = []
    for fullpath, filename, text in kb_docs:
        lines = split_to_lines(text)
        if len(lines) > MAX_LINES_PER_DOC:
            lines = lines[:MAX_LINES_PER_DOC]

        for ln in lines:
            ln_clean = clean_ws(ln)
            if len(ln_clean) < 15:
                continue

            toks = frozenset(tokenize(ln_clean))
            has_std = bool(STD_TOKEN_RE.search(ln_clean))
            has_std_ctx = bool(STD_CONTEXT_RE.search(ln_clean))
            has_def_ctx = bool(DEF_CONTEXT_RE.search(ln_clean))
            has_req_ctx = bool(REQ_CONTEXT_RE.search(ln_clean))

            idx.append(
                KBLine(
                    doc=filename,
                    fullpath=fullpath,
                    text=ln_clean,
                    tokens=toks,
                    has_std=has_std,
                    has_std_context=has_std_ctx,
                    has_def_context=has_def_ctx,
                    has_req_context=has_req_ctx,
                )
            )
    return idx


def build_or_load_kb_index(force_rebuild: bool = False) -> tuple[list[tuple[str, str, str]], list[KBLine]]:
    kb_docs = load_kb_docs(KB_DIR)

    if (not force_rebuild) and KB_INDEX_PATH.exists():
        try:
            with open(KB_INDEX_PATH, "rb") as f:
                cached = pickle.load(f)
            # basic sanity
            if isinstance(cached, list) and cached and isinstance(cached[0], KBLine):
                return kb_docs, cached
        except Exception:
            pass

    idx = build_kb_index(kb_docs)
    with open(KB_INDEX_PATH, "wb") as f:
        pickle.dump(idx, f)
    return kb_docs, idx


# =========================================================
# CANDIDATE SCORING (compare all lines)
# =========================================================
def score_line(q_tokens: set[str], line: KBLine) -> float:
    if not q_tokens:
        return 0.0
    overlap = len(q_tokens & set(line.tokens))
    if overlap <= 0:
        return 0.0

    base = overlap / max(3, len(q_tokens))  # normalized
    base += doc_priority_adjustment(line.doc)

    # bonus for requirement language
    if line.has_req_context:
        base += 0.06

    return base


def passes_intent_constraints(intent: str, line: KBLine, focus_term: str | None, q_raw: str) -> bool:
    t = line.text

    if intent == "which_standard":
        # Must mention a standard token (MBN/ISO/DIN...) and ideally the "according to/gemäß/nach" context
        if not line.has_std:
            return False
        # if question contains "in accordance/according/gemäß/nach", demand context too
        if any(p.search(q_raw) for p in WHICH_STANDARD_PATTERNS):
            if not (line.has_std_context or "in accordance" in q_raw.lower() or "according" in q_raw.lower()):
                # allow if line has explicit "nach/gemäß/according" anyway; already covered by has_std_context
                pass
        return True

    if intent == "definition":
        # Prefer explicit definition contexts if focus term exists
        if focus_term:
            if re.search(rf"(?i)\b{re.escape(focus_term)}\b", t) is None:
                return False
        return True

    if intent == "requirement":
        # Prefer lines with requirement markers
        return True

    return True


def pick_best_candidates(index: list[KBLine], question: str, intent: str, focus_term: str | None, top_k: int = 8) -> list[KBLine]:
    q_raw = question or ""
    q_tokens = expand_query_tokens(q_raw)

    scored = []
    for line in index:
        if not passes_intent_constraints(intent, line, focus_term, q_raw):
            continue
        s = score_line(q_tokens, line)
        if s > 0:
            # add intent-specific bonuses
            if intent == "which_standard":
                s += 0.20 if line.has_std_context else 0.08
            if intent == "definition" and line.has_def_context:
                s += 0.18
            if intent == "requirement" and line.has_req_context:
                s += 0.10
            scored.append((s, line))

    scored.sort(key=lambda x: x[0], reverse=True)

    # de-duplicate identical lines
    out = []
    seen = set()
    for s, line in scored:
        key = (line.doc.lower(), line.text.lower())
        if key in seen:
            continue
        seen.add(key)
        out.append(line)
        if len(out) >= top_k:
            break

    return out


# =========================================================
# DEFINITION EXTRACTION (explicit)
# =========================================================
def explicit_definition_from_text(term: str, text: str) -> str | None:
    if not term or not text:
        return None

    # TERM (Expansion)
    m = re.search(rf"(?i)\b{re.escape(term)}\b\s*\(\s*([^){{}}]]{{2,120}}?)\s*\)", text)
    if m:
        exp = clean_ws(m.group(1))
        if exp and len(exp) <= 140:
            return f"{term} = {exp}"

    # TERM stands for / steht für
    m = re.search(rf"(?i)\b{re.escape(term)}\b\s+(stands\s+for|steht\s+für)\s+([A-Za-zÄÖÜäöüß0-9][^.\n]{{3,140}})", text)
    if m:
        exp = clean_ws(m.group(2))
        return f"{term} = {exp}"

    # TERM = X
    m = re.search(rf"(?i)\b{re.escape(term)}\b\s*[:=]\s*([A-Za-zÄÖÜäöüß0-9][^.\n]{{3,140}})", text)
    if m:
        exp = clean_ws(m.group(1))
        return f"{term} = {exp}"

    return None


def pick_definition(index: list[KBLine], focus_term: str) -> tuple[str | None, str | None]:
    if not focus_term:
        return None, None

    # scan best candidates only (fast and deterministic)
    # prioritize lines that contain def context + term
    candidates = []
    for line in index:
        if re.search(rf"(?i)\b{re.escape(focus_term)}\b", line.text) and line.has_def_context:
            score = 1.0 + doc_priority_adjustment(line.doc)
            candidates.append((score, line))
    candidates.sort(key=lambda x: x[0], reverse=True)

    for _, line in candidates[:120]:
        d = explicit_definition_from_text(focus_term, line.text)
        if d:
            return d, line.doc

    # fallback: any line with TERM(...)
    for _, line in candidates[:120]:
        d = explicit_definition_from_text(focus_term, line.text)
        if d:
            return d, line.doc

    return None, None


# =========================================================
# SAFE EN output (no fake translation)
# =========================================================
def safe_en_from_de_line(line: str) -> str:
    s = clean_ws(line)
    if not s:
        return s

    # minimal deterministic substitutions (extend as you like)
    repl = [
        (r"\bNachweis\b", "evidence"),
        (r"\bAnforderung(en)?\b", "requirement(s)"),
        (r"\bDokumentation\b", "documentation"),
        (r"\bdokumentiert\b", "documented"),
        (r"\bentsprechend\b", "in accordance with"),
        (r"\bgemäß\b", "in accordance with"),
        (r"\bnach\b", "according to"),
        (r"\bStandard\b", "standard"),
        (r"\bNorm\b", "standard"),
    ]
    out = s
    for pat, rep in repl:
        out = re.sub(pat, rep, out, flags=re.IGNORECASE)

    # if still very German, tag as DE original
    de_markers = [" der ", " die ", " das ", " und ", " nicht ", " wird ", " wurde ", " kann ", " soll ", " muss "]
    if sum(m in (" " + out.lower() + " ") for m in de_markers) >= 2:
        return f"(DE original) {s}"
    return out


# =========================================================
# ANSWER ASSEMBLY (your approach: compare candidates then write)
# =========================================================
def build_bilingual_reply(greeting_name: str, signature_name: str, intent: str,
                         bullets_de: list[str],
                         definition_line: str | None = None,
                         ask_clarification: bool = False) -> str:
    greeting_name = greeting_name or "Sustainable-procurement"
    signature_name = signature_name or "Shubham"

    # IMPORTANT: redact only content lines, not greeting/signature
    def _redact_list(lines: list[str]) -> list[str]:
        return [redact_sensitive_remove(x) for x in lines]

    de_lines = [
        f"Hallo {greeting_name},",
        "ich hoffe, es geht Ihnen gut.",
        "",
    ]

    if intent == "definition" and definition_line:
        de_lines += _redact_list([definition_line])
    else:
        de_lines += [f"- {x}" for x in _redact_list(bullets_de) if x]

    if ask_clarification:
        de_lines += ["", "Falls Sie mir den Dokumentennamen oder den relevanten Abschnitt nennen, kann ich die Antwort gezielt präzisieren."]

    de_lines += ["", "Mit freundlichen Grüßen", signature_name]

    en_lines = [
        f"Hello {greeting_name},",
        "I hope you are doing well.",
        "",
    ]

    if intent == "definition" and definition_line:
        en_lines += [definition_line]  # usually already clean: "PPA = Power Purchase Agreement"
    else:
        en_lines += ["Key points:"]
        for b in bullets_de[:6]:
            en_lines += [f"- {safe_en_from_de_line(redact_sensitive_remove(b))}"]

    if ask_clarification:
        en_lines += ["", "If you share the document name or the relevant section, I can refine the answer precisely."]

    en_lines += ["", "Best regards,", signature_name]

    return "\n".join(de_lines).strip() + "\n\n---\n\n" + "\n".join(en_lines).strip()


def build_answer_from_kb(index: list[KBLine], question_text: str) -> str:
    q = clean_ws(question_text)
    intent = detect_intent(q)
    focus = extract_focus_term(q)

    definition_line = None
    ask_clarification = False

    # Definition-first (explicit)
    if intent == "definition" and focus:
        definition_line, _src = pick_definition(index, focus)

    # Compare candidates across ALL docs/lines (your requested approach)
    cands = pick_best_candidates(index, q, intent=intent, focus_term=focus, top_k=8)

    bullets = []
    if intent == "definition":
        if not definition_line:
            # try turning top candidate into TERM = ...
            for c in cands:
                if focus:
                    d = explicit_definition_from_text(focus, c.text)
                    if d:
                        definition_line = d
                        break
            if not definition_line:
                bullets = [c.text for c in cands[:3]]
                ask_clarification = True

    elif intent == "which_standard":
        # We want the most direct standard-containing line
        bullets = [c.text for c in cands[:4]]
        if not bullets:
            ask_clarification = True

    else:
        bullets = [c.text for c in cands[:5]]
        if not bullets:
            ask_clarification = True

    return build_bilingual_reply(
        greeting_name="Sustainable-procurement",
        signature_name=safe_firstname_from_email(TARGET_MAILBOX),
        intent=intent,
        bullets_de=bullets,
        definition_line=definition_line,
        ask_clarification=ask_clarification
    )


# =========================================================
# OUTLOOK HELPERS
# =========================================================
def get_sender_smtp(mail) -> str:
    try:
        addr = (mail.SenderEmailAddress or "").lower()
        if addr.startswith("/o="):
            ex = mail.Sender.GetExchangeUser()
            if ex:
                return (ex.PrimarySmtpAddress or "").lower()
        return addr
    except Exception:
        return (mail.SenderEmailAddress or "").lower()


def add_processed_category(mail):
    try:
        cats = mail.Categories or ""
        if PROCESSED_CATEGORY.lower() not in cats.lower():
            mail.Categories = (cats + "," + PROCESSED_CATEGORY).strip(",")
        mail.Save()
    except Exception:
        pass


def mark_read(mail):
    try:
        mail.UnRead = False
        mail.Save()
    except Exception:
        pass


def get_target_folder():
    ns = win32.Dispatch("Outlook.Application").GetNamespace("MAPI")

    target_store = None
    for st in ns.Stores:
        if TARGET_MAILBOX.lower() in (st.DisplayName or "").lower():
            target_store = st
            break

    if not target_store:
        print("Available stores:")
        for st in ns.Stores:
            print(" -", st.DisplayName)
        raise SystemExit("Target mailbox not found. Adjust TARGET_MAILBOX.")

    inbox = target_store.GetDefaultFolder(6)  # Inbox

    if WATCH_FOLDER_NAME.lower() == "inbox":
        return ns, inbox, target_store.DisplayName, "Inbox"

    for f in inbox.Folders:
        if (f.Name or "").lower() == WATCH_FOLDER_NAME.lower():
            return ns, f, target_store.DisplayName, f.Name

    raise SystemExit(f"Subfolder '{WATCH_FOLDER_NAME}' not found under Inbox.")


def get_account_for_mailbox(ns, mailbox_substring: str):
    try:
        for acc in ns.Session.Accounts:
            smtp = (getattr(acc, "SmtpAddress", "") or "").lower()
            if mailbox_substring.lower() in smtp or smtp in mailbox_substring.lower():
                return acc
    except Exception:
        pass
    return None


def send_self_notification(ns, from_mailbox: str, to_addr: str, orig_subject: str, requester_email: str):
    msg = ns.Application.CreateItem(0)
    msg.To = to_addr
    msg.Subject = f"Draft created (review needed): {orig_subject}"
    msg.Body = (
        "A draft reply has been created in Outlook.\n\n"
        f"Original subject: {orig_subject}\n"
        f"Requester: {requester_email}\n\n"
        "Please review the draft carefully before sending.\n"
    )
    acc = get_account_for_mailbox(ns, from_mailbox)
    if acc:
        try:
            msg.SendUsingAccount = acc
        except Exception:
            pass
    msg.Send()


def create_outlook_task_reminder(ns, subject: str, days: int = 2):
    try:
        task = ns.Application.CreateItem(3)  # olTaskItem
        task.Subject = f"Reminder: review/send draft for '{subject}'"
        task.DueDate = (datetime.now() + timedelta(days=days)).date()
        task.ReminderSet = True
        task.ReminderTime = datetime.now() + timedelta(days=days)
        task.Body = "A draft reply was created by the bot. Please review and send it."
        task.Save()
    except Exception:
        pass


# =========================================================
# BOT RUN
# =========================================================
def run_bot_once(force_rebuild_index: bool = False):
    import time
    time.sleep(STARTUP_DELAY_SEC)

    print("Loading KB from:", KB_DIR)
    kb_docs, kb_index = build_or_load_kb_index(force_rebuild=force_rebuild_index)
    print("KB docs:", len(kb_docs), "| KB indexed lines:", len(kb_index))
    print("KB index cache:", KB_INDEX_PATH)

    ns, folder, store_name, folder_name = get_target_folder()
    print(f"Mailbox={store_name} | Folder={folder_name}")

    items = folder.Items
    items.Sort("[ReceivedTime]", True)

    drafted = 0
    checked = 0

    for mail in items:
        checked += 1
        if checked > SCAN_LIMIT:
            break
        if drafted >= PROCESS_PER_RUN:
            break

        try:
            if getattr(mail, "Class", None) != 43:
                continue

            subject = mail.Subject or ""
            unread = bool(getattr(mail, "UnRead", False))
            cats = (mail.Categories or "")

            if PROCESSED_CATEGORY.lower() in cats.lower():
                continue
            if REQUIRE_UNREAD and not unread:
                continue
            if REQUIRE_STRICT_SUBJECT and not strict_subject_is_bot(subject):
                continue

            sender = get_sender_smtp(mail)
            greeting_name = safe_firstname_from_email(sender)

            body_text = clean_html_to_text(mail.HTMLBody or "")
            # keep only top part (strip quoted chains)
            body_top = re.split(r"(?i)\b(von:|from:|gesendet:|sent:|-----original message-----)\b", body_text)[0].strip()
            question = body_top if body_top else body_text

            reply_text = build_answer_from_kb(kb_index, question_text=question)

            # Insert real greeting_name deterministically
            reply_text = reply_text.replace("Hallo Sustainable-procurement", f"Hallo {greeting_name}")
            reply_text = reply_text.replace("Hello Sustainable-procurement", f"Hello {greeting_name}")

            html_answer = format_outlook_html(reply_text)

            reply = mail.Reply()
            reply.HTMLBody = f"<div>{html_answer}</div><hr>" + reply.HTMLBody
            reply.Save()

            mark_read(mail)
            add_processed_category(mail)

            drafted += 1
            print("Draft created for:", subject)

            if SELF_NOTIFY:
                try:
                    send_self_notification(ns, TARGET_MAILBOX, SELF_NOTIFY_TO, subject, sender)
                except Exception as e:
                    print("Self notification failed:", e)

            if CREATE_REMINDER_TASK:
                create_outlook_task_reminder(ns, subject, REMINDER_DAYS)

        except Exception as e:
            print("Mail error:", getattr(mail, "Subject", "<no subject>"), "-", repr(e))

    print(f"Done. Checked={checked}, Drafted={drafted}")


# Usage:
# run_bot_once(force_rebuild_index=True)   # first time or after KB changes
# run_bot_once()                           # normal runs (uses cached index)
