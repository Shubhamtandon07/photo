# ================================
# .MSG -> ONE .DOCX per email
# - Redact personal/sensitive info in subject+body+attachment text
# - Append attachment text (pdf/xlsx/docx/txt/csv) at end
# - Jupyter-safe (no argparse)
# - Python 3.14 compatible
# ================================

import os
import re
import sys
import json
import traceback
from pathlib import Path
from datetime import datetime

# ---------- CONFIG ----------
MSG_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Mails Rasmus"
OUT_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Mails Rasmus\_exports"

# Output folder will be unique per run (so trials don't overwrite)
RUN_PREFIX = "msg_to_docx_redacted"

# Extraction limits
BODY_MAX_CHARS = 250_000
ATTACH_TEXT_MAX_CHARS = 12_000
PDF_MAX_PAGES = 30
XLSX_MAX_SHEETS = 5
XLSX_MAX_ROWS = 250
XLSX_MAX_COLS = 30

# ---------- OPTIONAL IMPORTS (auto-skip if missing) ----------
def try_import(name):
    try:
        __import__(name)
        return sys.modules[name]
    except Exception:
        return None

extract_msg = try_import("extract_msg")

docx_mod = None
try:
    import docx as docx_mod  # python-docx
except Exception:
    docx_mod = None

pdfplumber = try_import("pdfplumber")
openpyxl = try_import("openpyxl")

import html as html_mod  # for html unescape


# ---------- UTIL ----------
def now_ts():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def ensure_dir(p: Path) -> Path:
    p.mkdir(parents=True, exist_ok=True)
    return p

def safe_str(x) -> str:
    if x is None:
        return ""
    try:
        return str(x)
    except Exception:
        try:
            return repr(x)
        except Exception:
            return ""

def sanitize_filename(name: str, max_len: int = 160) -> str:
    name = safe_str(name).strip()
    name = re.sub(r"[\\/:*?\"<>|]+", "_", name)
    name = re.sub(r"\s+", " ", name).strip()
    if len(name) > max_len:
        name = name[:max_len].rstrip()
    return name or "message"

def log_line(log_path: Path, line: str):
    with log_path.open("a", encoding="utf-8") as f:
        f.write(f"[{now_ts()}] {line}\n")


# ---------- HTML->TEXT (lightweight) ----------
def strip_html_to_text(html: str) -> str:
    h = safe_str(html)
    h = re.sub(r"(?is)<(script|style).*?>.*?</\1>", " ", h)
    h = re.sub(r"(?i)<br\s*/?>", "\n", h)
    h = re.sub(r"(?i)</p\s*>", "\n\n", h)
    h = re.sub(r"(?is)<.*?>", " ", h)
    try:
        h = html_mod.unescape(h)
    except Exception:
        pass
    h = re.sub(r"[ \t]+\n", "\n", h)
    h = re.sub(r"\n{3,}", "\n\n", h)
    h = re.sub(r"[ \t]{2,}", " ", h)
    return h.strip()


# ---------- BODY EXTRACTION (plain -> html -> rtf fallback) ----------
def body_best_effort(msg) -> str:
    b = safe_str(getattr(msg, "body", "") or "")
    if b.strip():
        return b.strip()

    hb = safe_str(getattr(msg, "htmlBody", "") or "")
    if hb.strip():
        t = strip_html_to_text(hb)
        if t.strip():
            return t.strip()

    rb = getattr(msg, "rtfBody", None)
    if rb is not None:
        try:
            if isinstance(rb, (bytes, bytearray)):
                rb = rb.decode("utf-8", errors="ignore")
            rb = safe_str(rb).strip()
            if rb:
                # crude rtf cleanup
                rb2 = re.sub(r"{\\.*?}", " ", rb)
                rb2 = re.sub(r"\\[a-zA-Z]+\d*\s?", " ", rb2)
                rb2 = re.sub(r"[{}]", " ", rb2)
                rb2 = re.sub(r"\s{2,}", " ", rb2).strip()
                if rb2:
                    return rb2
        except Exception:
            pass

    return ""


# ---------- REDACTION ----------
LEGAL_SUFFIXES = {
    "gmbh", "ag", "kg", "kgaa", "se", "inc", "ltd", "llc", "plc", "bv", "nv", "oy", "sas", "sarl"
}

STREET_WORDS = [
    "straße", "strasse", "str.", "street", "st.", "weg", "allee", "platz", "gasse", "ring",
    "chaussee", "road", "rd", "avenue", "av.", "boulevard", "blvd"
]

HEADER_CUE_LINES = [
    "von:", "from:",
    "an:", "to:",
    "cc:", "kopie:", "bcc:",
    "gesendet:", "sent:",
    "betreff:", "subject:",
    "priorität:", "priority:",
    "mail to:", "mailto:"
]

def redact_names_heuristic(text: str) -> str:
    """
    Heuristic: redact 2-3 token "Person-like" names with Capitalized words,
    but skip if it looks like a company (GmbH/AG/etc).
    """
    # match 2-3 capitalized words (incl. umlauts)
    pat = re.compile(r"\b([A-ZÄÖÜ][a-zäöüß]+(?:\s+[A-ZÄÖÜ][a-zäöüß]+){1,2})\b")

    def repl(m):
        phrase = m.group(1)
        low = phrase.lower()
        # Skip if contains legal suffix word after/inside phrase
        for sfx in LEGAL_SUFFIXES:
            if f" {sfx}" in low or low.endswith(sfx):
                return phrase
        # Skip common non-person words
        if any(w in low for w in ["mercedes", "benz", "plant", "werk", "procurement", "supplier", "quality"]):
            return phrase
        return "[REDACTED_NAME]"

    return pat.sub(repl, text)

def redact_text(text: str) -> str:
    t = safe_str(text)

    # 1) Remove common header blocks line-by-line (Von/An/Cc/Gesendet/Betreff etc.)
    lines = t.splitlines()
    cleaned = []
    skip_block = False

    for line in lines:
        l = line.strip()
        low = l.lower()

        # If we detect typical Outlook header sections, remove those lines
        if any(low.startswith(cue) for cue in HEADER_CUE_LINES):
            continue

        # Some mails contain multi-line header blocks; remove until blank line
        if low.startswith("_____") or low.startswith("----") or low.startswith("original message"):
            # keep separators but not required
            continue

        cleaned.append(line)

    t = "\n".join(cleaned)

    # 2) Emails
    t = re.sub(r"\b[a-zA-Z0-9._%+\-]+@[a-zA-Z0-9.\-]+\.[a-zA-Z]{2,}\b", "[REDACTED_EMAIL]", t)

    # 3) Phone numbers (broad, but avoids short numbers)
    # patterns like +49 151 58 60..., (0711) 12345, 050-xxxx, etc
    t = re.sub(r"(?<!\d)(\+?\d[\d\s()./\-]{6,}\d)(?!\d)", "[REDACTED_PHONE]", t)

    # 4) IBAN
    t = re.sub(r"\b[A-Z]{2}\d{2}[A-Z0-9]{11,30}\b", "[REDACTED_IBAN]", t)

    # 5) Postal code + city (Germany-ish)
    t = re.sub(r"\b\d{5}\s+[A-Za-zÄÖÜäöüß][A-Za-zÄÖÜäöüß\-]{2,}\b", "[REDACTED_LOCATION]", t)

    # 6) Street-like addresses (street word + number)
    street_word_re = "|".join([re.escape(w) for w in STREET_WORDS])
    t = re.sub(
        rf"\b([A-Za-zÄÖÜäöüß][A-Za-zÄÖÜäöüß\-\s]{{2,60}}\s(?:{street_word_re})\s*\d{{1,4}}[A-Za-z]?)\b",
        "[REDACTED_ADDRESS]",
        t,
        flags=re.IGNORECASE
    )

    # 7) Mercedes internal org codes / cost center-ish
    t = re.sub(r"\b0\d{2}-[A-Z0-9]+\b", "[REDACTED_INTERNAL]", t)          # 050-G277 etc
    t = re.sub(r"\b0\d{2}/[A-Z]{2,}\b", "[REDACTED_INTERNAL]", t)          # 050/HPC
    t = re.sub(r"\bMP/RM\d\b", "[REDACTED_INTERNAL]", t)

    # 8) Greeting lines: keep greeting, remove the name part
    t = re.sub(r"(?im)^(hallo|hi|guten morgen|guten tag|sehr geehrte[rn]?|dear|hello)\s+.+?$",
               r"\1 [REDACTED_NAME]", t)

    # 9) Signature closings: remove name line(s) after closing phrase
    t = re.sub(r"(?im)^(mit freundlichen grüßen|freundliche grüße|best regards|kind regards|vg|lg|br)\s*$",
               r"\1", t)
    # common "VG Name" in same line
    t = re.sub(r"(?im)^(vg|lg|br)\s+.+$", r"\1 [REDACTED_NAME]", t)

    # 10) Heuristic person names in running text (2-3 capitalized tokens)
    t = redact_names_heuristic(t)

    # 11) Collapse repeated placeholders
    t = re.sub(r"(\[REDACTED_[A-Z_]+\])(\s+\1)+", r"\1", t)

    # 12) Cleanup extra spaces
    t = re.sub(r"[ \t]{2,}", " ", t)
    t = re.sub(r"\n{4,}", "\n\n\n", t)

    return t.strip()


# ---------- ATTACHMENT EXTRACTION ----------
def extract_attachment_text(path: Path) -> str:
    if not path.exists() or not path.is_file():
        return ""

    ext = path.suffix.lower()

    # TXT/CSV
    if ext in [".txt", ".csv", ".log"]:
        try:
            return path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            try:
                return path.read_text(encoding="latin-1", errors="ignore")
            except Exception:
                return ""

    # PDF
    if ext == ".pdf" and pdfplumber is not None:
        try:
            parts = []
            with pdfplumber.open(str(path)) as pdf:
                for p in pdf.pages[:PDF_MAX_PAGES]:
                    txt = p.extract_text() or ""
                    if txt.strip():
                        parts.append(txt)
            return "\n\n".join(parts).strip()
        except Exception:
            return ""

    # XLSX/XLSM
    if ext in [".xlsx", ".xlsm"] and openpyxl is not None:
        try:
            wb = openpyxl.load_workbook(str(path), data_only=True, read_only=True)
            out = []
            for ws in wb.worksheets[:XLSX_MAX_SHEETS]:
                out.append(f"[Sheet] {ws.title}")
                for r_i, row in enumerate(ws.iter_rows(values_only=True), start=1):
                    if r_i > XLSX_MAX_ROWS:
                        break
                    vals = []
                    for v in row[:XLSX_MAX_COLS]:
                        if v is None:
                            continue
                        s = safe_str(v).strip()
                        if s:
                            vals.append(s)
                    if vals:
                        out.append(" | ".join(vals))
            return "\n".join(out).strip()
        except Exception:
            return ""

    # DOCX
    if ext == ".docx" and docx_mod is not None:
        try:
            d = docx_mod.Document(str(path))
            paras = [p.text for p in d.paragraphs if p.text and p.text.strip()]
            return "\n".join(paras).strip()
        except Exception:
            return ""

    # unsupported
    return ""


# ---------- WRITE DOCX ----------
def add_text_preserve_lines(doc, text: str):
    # Word doesn't preserve \n inside one paragraph reliably for your use-case;
    # add paragraph per line for readability.
    for line in (text or "").splitlines():
        doc.add_paragraph(line)

def msg_to_docx_one_file(msg_path: Path, out_docx: Path, att_root: Path, log_path: Path):
    # parse message
    m = extract_msg.Message(str(msg_path))

    # Some versions need process(); some don't.
    proc = getattr(m, "process", None)
    if callable(proc):
        proc()

    subject = safe_str(getattr(m, "subject", "") or "").strip()
    if not subject:
        subject = msg_path.stem

    date = safe_str(getattr(m, "date", "") or "").strip()

    # Body best effort (try plain/html/rtf)
    body = body_best_effort(m)
    body = (body or "")[:BODY_MAX_CHARS]

    # redact
    subject_r = redact_text(subject)
    body_r = redact_text(body)

    # attachments: save then extract text
    attachments_info = []
    msg_att_dir = ensure_dir(att_root / sanitize_filename(msg_path.stem))

    try:
        saver = getattr(m, "saveAttachments", None)
        if callable(saver):
            try:
                saver(customPath=str(msg_att_dir))
            except TypeError:
                try:
                    saver(str(msg_att_dir))
                except Exception:
                    pass

        # read saved attachment files
        for fp in sorted(msg_att_dir.glob("*")):
            if not fp.is_file():
                continue
            ext = fp.suffix.lower()
            if ext not in [".pdf", ".xlsx", ".xlsm", ".docx", ".txt", ".csv", ".log"]:
                continue

            raw = extract_attachment_text(fp)
            if raw.strip():
                red = redact_text(raw)[:ATTACH_TEXT_MAX_CHARS]
            else:
                red = ""

            attachments_info.append({
                "name": fp.name,
                "path": str(fp),
                "text": red
            })

    except Exception as e:
        log_line(log_path, f"WARNING: attachment extraction failed for {msg_path.name}: {repr(e)}")

    # write docx
    doc = docx_mod.Document()
    doc.add_heading(subject_r, level=1)

    if date:
        doc.add_paragraph(f"Date: {redact_text(date)}")

    doc.add_paragraph("")  # spacer
    doc.add_heading("Body (redacted)", level=2)
    if body_r.strip():
        add_text_preserve_lines(doc, body_r)
    else:
        doc.add_paragraph("(no usable body text extracted)")

    # Append attachments
    doc.add_paragraph("")
    doc.add_heading("Attachments (redacted excerpts)", level=2)
    if attachments_info:
        for a in attachments_info:
            doc.add_heading(a["name"], level=3)
            if a["text"].strip():
                add_text_preserve_lines(doc, a["text"])
            else:
                doc.add_paragraph("(no text extracted or unsupported file type)")
            doc.add_paragraph("")
    else:
        doc.add_paragraph("(no supported attachments found)")

    out_docx.parent.mkdir(parents=True, exist_ok=True)
    doc.save(str(out_docx))

    # close msg if supported
    try:
        close_fn = getattr(m, "close", None)
        if callable(close_fn):
            close_fn()
    except Exception:
        pass


# ---------- MAIN RUN ----------
def run_all():
    if extract_msg is None:
        raise RuntimeError("Missing extract-msg. Install: py -m pip install -U extract-msg")
    if docx_mod is None:
        raise RuntimeError("Missing python-docx. Install: py -m pip install -U python-docx")

    src = Path(MSG_DIR)
    out_root = Path(OUT_DIR)

    if not src.exists():
        raise FileNotFoundError(f"MSG_DIR not found: {src}")

    run_id = datetime.now().strftime(f"{RUN_PREFIX}_%Y%m%d_%H%M%S")
    run_dir = ensure_dir(out_root / run_id)

    docx_dir = ensure_dir(run_dir / "docx")
    att_root = ensure_dir(run_dir / "attachments_saved")
    log_path = run_dir / "errors.log"
    index_path = run_dir / "index.jsonl"

    msg_files = sorted(src.rglob("*.msg"))
    print(f"Found .msg files: {len(msg_files)}")
    print(f"Output run folder: {run_dir}")

    if not msg_files:
        print("No .msg found. Check your MSG_DIR path or OneDrive availability (make files offline).")
        return

    ok = 0
    fail = 0

    with index_path.open("w", encoding="utf-8") as idx:
        for i, p in enumerate(msg_files, start=1):
            try:
                base = sanitize_filename(p.stem)
                out_docx = docx_dir / f"{base}__{i:05d}.docx"

                msg_to_docx_one_file(p, out_docx, att_root, log_path)

                rec = {
                    "source": str(p),
                    "out_docx": str(out_docx),
                    "generated": now_ts(),
                }
                idx.write(json.dumps(rec, ensure_ascii=False) + "\n")

                ok += 1
                if i % 25 == 0:
                    print(f"Progress: {i}/{len(msg_files)} | ok={ok} fail={fail}")

            except Exception as e:
                fail += 1
                log_line(log_path, f"ERROR: {p.name} -> {repr(e)}")
                log_line(log_path, traceback.format_exc())

    print(f"Done. ok={ok} fail={fail}")
    if fail:
        print(f"See errors: {log_path}")

# ---- RUN ----
run_all()
