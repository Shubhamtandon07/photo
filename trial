# -*- coding: utf-8 -*-
"""
ONE SCRIPT: sanitize + de-risk Outlook .msg email chains for training use.

- Input: folder full of .msg files (recursively)
- Output: EXACTLY 1 HTML per input .msg (no duplicates)
- Output contains:
  - Subject (sanitized)
  - Cleaned BODY text (chain-aware, removes Von/An/Cc/Gesendet/Betreff etc.)
  - Sensitive info removed (names, emails, phones, urls/domains, refs/ids, iban, money)
  - Segments labeled QUESTION / ANSWER (heuristic, computed bottom->top)
- No OCR / no image parsing.

Run:
  python sanitize_msgs.py
"""

import re
import json
import hashlib
from datetime import datetime
from pathlib import Path
from html import escape

# =========================
# EDIT THESE
# =========================
MSG_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Mails Rasmus"
OUT_DIR = r"C:\Users\SHTANDO\OneDrive - Mercedes-Benz (corpdir.onmicrosoft.com)\DWT_MP_RM1 - Dokumente\Project Chatbot\Available data\Mails Rasmus\_exports"

OUT_SUBFOLDER = "sanitized_one_per_mail"   # exactly 1 HTML per msg
WRITE_JSONL = True                         # also write training-friendly JSONL
JSONL_NAME = "dataset.jsonl"
# =========================


# ---------- Patterns ----------
EMAIL_RE = re.compile(r"\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\.[A-Z]{2,}\b", re.I)
URL_RE = re.compile(r"\bhttps?://[^\s<>()]+\b", re.I)
WWW_RE = re.compile(r"\bwww\.[^\s<>()]+\b", re.I)
DOMAIN_RE = re.compile(r"\b(?:[A-Z0-9-]+\.)+[A-Z]{2,}\b", re.I)

PHONE_RE = re.compile(r"(?:(?:\+|00)\d{1,3}[\s\-]?)?(?:\(?\d{2,6}\)?[\s\-]?)?\d[\d\s\-]{6,}\d")
IBAN_RE = re.compile(r"\b[A-Z]{2}\d{2}[A-Z0-9]{11,30}\b", re.I)

MONEY_RE = re.compile(
    r"(?i)\b(?:EUR|USD|GBP|CHF)\s*\d[\d\.\,\s]*\b"
    r"|\b\d[\d\.\,\s]*\s*(?:€|EUR|USD|GBP|CHF)\b"
    r"|\b€\s*\d[\d\.\,\s]*\b"
)
REF_RE = re.compile(
    r"\b(?:PO|PR|NCR|Ticket|Case|Req|Request|Material|Part|Supplier|Portal|Round|ID|Ref|SP)\s*[:#]?\s*"
    r"[A-Za-z0-9\-_/]*\d[A-Za-z0-9\-_/]*\b",
    re.I
)

# Names (heuristics)
TITLE_NAME_RE = re.compile(r"\b(?:Mr|Mrs|Ms|Miss|Dr|Prof|Herr|Frau)\.?\s+[A-ZÄÖÜ][a-zäöüß]+(?:\s+[A-ZÄÖÜ][a-zäöüß]+){0,2}\b")
COMMA_NAME_RE = re.compile(r"\b[A-ZÄÖÜ][a-zäöüß]+,\s+[A-ZÄÖÜ][a-zäöüß]+(?:\s+[A-ZÄÖÜ][a-zäöüß]+){0,2}\b")
NAME_RE = re.compile(r"\b[A-ZÄÖÜ][a-zäöüß]{2,}\s+[A-ZÄÖÜ][a-zäöüß]{2,}(?:\s+[A-ZÄÖÜ][a-zäöüß]{2,}){0,1}\b")

# Greeting line name: "Hallo X", "Hi X", "Guten Morgen X"
GREET_NAME_RE = re.compile(
    r"(?im)^\s*(?:hallo|hi|hello|guten\s+morgen|guten\s+tag|servus|moin)\s+([A-ZÄÖÜ][^\n,]{1,40})[,!]*\s*$"
)

# Signature blocks (remove from first sign-off to end)
SIGNOFF_RE = re.compile(
    r"(?is)\n\s*(mit\s+freundlichen\s+gr[üu]ßen|best\s+regards|kind\s+regards|vg|lg|br|gr[üu]ße)\b.*$"
)

# Outlook quoted header lines inside body (DE/EN)
HEADER_LINE_RE = re.compile(
    r"(?im)^\s*(von|from|an|to|cc|kopie|gesendet|sent|betreff|subject|priorit[aä]t|importance)\s*:\s.*$"
)

SEP_RE = re.compile(r"(?m)^\s*_{5,}\s*$|^\s*-{5,}\s*$|^\s*={5,}\s*$")

QUESTION_CUES = re.compile(r"(?i)\b(kannst|könnt|können|bitte|frage|fragen|could you|can you|please|may you|need|required|requirement)\b")
ANSWER_CUES = re.compile(r"(?i)\b(danke|anbei|unten|siehe|hier|we recommend|please ensure|to achieve|requirements|you need to|must|soll|muss|empfehlen|information|antwort)\b")


# ---------- helpers ----------
def now_ts() -> str:
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def to_text(x) -> str:
    """Normalize ANY value to a safe unicode string."""
    if x is None:
        return ""
    if isinstance(x, str):
        return x
    if isinstance(x, bytes):
        # try utf-8, then latin-1 fallback
        try:
            return x.decode("utf-8", errors="ignore")
        except Exception:
            return x.decode("latin-1", errors="ignore")
    # sometimes extract_msg returns objects; force str
    try:
        return str(x)
    except Exception:
        return ""


def safe_out_name(src_path: Path) -> str:
    raw = src_path.stem
    cleaned = re.sub(r"[\\/:*?\"<>|]+", "_", raw)
    cleaned = re.sub(r"\s+", " ", cleaned).strip()[:80]
    h = hashlib.sha1(str(src_path).encode("utf-8", errors="ignore")).hexdigest()[:8]
    if not cleaned:
        cleaned = "mail"
    return f"{cleaned}__{h}.html"


def clean_ws(s: str) -> str:
    s = to_text(s)
    s = s.replace("\r\n", "\n").replace("\r", "\n")

    # Fix spaced-out HTML artifacts like: "h t m l  x m l n s : ..."
    fixed_lines = []
    for ln in s.splitlines():
        t = ln.strip()
        if t and len(t) > 40:
            space_ratio = t.count(" ") / max(1, len(t))
            if space_ratio > 0.25 and re.search(r"(h\s*t\s*m\s*l|x\s*m\s*l\s*n\s*s)", t, re.I):
                ln = t.replace(" ", "")
        fixed_lines.append(ln)
    s = "\n".join(fixed_lines)

    # remove control chars (keep newline)
    s = re.sub(r"[\x00-\x08\x0b\x0c\x0e-\x1f]", " ", s)
    s = re.sub(r"[ \t]+", " ", s)
    s = re.sub(r"\n{3,}", "\n\n", s)
    return s.strip()


def html_to_text(html: str) -> str:
    html = to_text(html)
    if not html:
        return ""
    txt = re.sub(r"(?is)<(script|style).*?>.*?</\1>", " ", html)
    txt = re.sub(r"(?is)<br\s*/?>", "\n", txt)
    txt = re.sub(r"(?is)</p\s*>", "\n\n", txt)
    txt = re.sub(r"(?is)<[^>]+>", " ", txt)
    return clean_ws(txt)


def parse_msg(msg_path: Path) -> dict:
    """
    Parse .msg using extract-msg. Handles version differences.
    """
    import extract_msg  # will raise if missing

    m = extract_msg.Message(str(msg_path))

    # Some versions need .extract(); some auto-process
    if hasattr(m, "extract") and callable(getattr(m, "extract")):
        try:
            m.extract()
        except Exception:
            pass

    subject = to_text(getattr(m, "subject", ""))
    body = to_text(getattr(m, "body", ""))
    html_body = to_text(getattr(m, "htmlBody", ""))
    rtf_body = to_text(getattr(m, "rtfBody", ""))

    # Close if available
    if hasattr(m, "close") and callable(getattr(m, "close")):
        try:
            m.close()
        except Exception:
            pass

    return {"subject": subject, "body": body, "htmlBody": html_body, "rtfBody": rtf_body}


def pick_best_body(parsed: dict) -> str:
    body = clean_ws(parsed.get("body", ""))
    html_body = parsed.get("htmlBody", "") or ""
    rtf_body = clean_ws(parsed.get("rtfBody", ""))

    # Prefer htmlBody if body is too short
    if len(body) < 60 and html_body:
        body2 = html_to_text(html_body)
        if len(body2) > len(body):
            return body2

    # If body contains HTML markup, convert
    if "<html" in body.lower() or "<body" in body.lower() or "<div" in body.lower():
        body2 = html_to_text(body)
        if body2:
            return body2

    # Fallback to RTF if better
    if len(body) < 60 and len(rtf_body) > len(body):
        return rtf_body

    return body


def strip_headers_and_signatures(text: str) -> str:
    t = clean_ws(text)
    if not t:
        return ""
    t = HEADER_LINE_RE.sub("", t)
    t = SEP_RE.sub("", t)
    t = SIGNOFF_RE.sub("", t)
    return clean_ws(t)


def redact_text(text: str) -> tuple[str, dict]:
    """
    Remove sensitive info completely (do not leave [PERSON] etc.)
    """
    stats = {"emails": 0, "urls": 0, "domains": 0, "phones": 0, "iban": 0, "money": 0, "refs": 0, "names": 0}
    t = clean_ws(text)

    # Greeting name removal
    def _greet_sub(m):
        stats["names"] += 1
        whole = m.group(0)
        name_part = m.group(1)
        return whole.replace(name_part, "").strip()

    t = GREET_NAME_RE.sub(_greet_sub, t)

    for rx in (TITLE_NAME_RE, COMMA_NAME_RE, NAME_RE):
        found = len(rx.findall(t))
        if found:
            stats["names"] += found
            t = rx.sub("", t)

    found = len(EMAIL_RE.findall(t))
    if found:
        stats["emails"] += found
        t = EMAIL_RE.sub("", t)

    found = len(URL_RE.findall(t)) + len(WWW_RE.findall(t))
    if found:
        stats["urls"] += found
        t = URL_RE.sub("", t)
        t = WWW_RE.sub("", t)

    found = len(DOMAIN_RE.findall(t))
    if found:
        stats["domains"] += found
        t = DOMAIN_RE.sub("", t)

    found = len(PHONE_RE.findall(t))
    if found:
        stats["phones"] += found
        t = PHONE_RE.sub("", t)

    found = len(IBAN_RE.findall(t))
    if found:
        stats["iban"] += found
        t = IBAN_RE.sub("", t)

    found = len(MONEY_RE.findall(t))
    if found:
        stats["money"] += found
        t = MONEY_RE.sub("", t)

    found = len(REF_RE.findall(t))
    if found:
        stats["refs"] += found
        t = REF_RE.sub("", t)

    # Cleanup
    t = re.sub(r"\(\s*\)", "", t)
    t = re.sub(r"[ \t]{2,}", " ", t)
    t = re.sub(r"\n{3,}", "\n\n", t)
    return clean_ws(t), stats


def split_chain_blocks(text: str) -> list[str]:
    """
    Split email chain into blocks on "Von:" / "From:" occurrences inside body.
    """
    t = clean_ws(text)
    if not t:
        return []
    split_rx = re.compile(r"(?im)^\s*(von|from)\s*:\s")
    parts = split_rx.split(t)

    if len(parts) == 1:
        return [t]

    blocks = []
    head = parts[0].strip()
    if head:
        blocks.append(head)

    i = 1
    while i + 1 < len(parts):
        key = parts[i]
        rest = parts[i + 1]
        block = (key + ": " + rest).strip()
        if block:
            blocks.append(block)
        i += 2

    return [b.strip() for b in blocks if b.strip()]


def label_blocks_heuristic(blocks: list[str]) -> list[dict]:
    """
    Label blocks QUESTION/ANSWER.
    Requirement: "question starts from bottom not top" => scoring bottom->top.
    """
    if not blocks:
        return []

    rev = list(reversed(blocks))
    labeled_rev = []

    for b in rev:
        txt = b.strip()
        if len(txt) < 20:
            continue

        q_score = 0
        a_score = 0

        if "?" in txt:
            q_score += 2
        if QUESTION_CUES.search(txt):
            q_score += 2
        if ANSWER_CUES.search(txt):
            a_score += 2
        if re.match(r"(?i)^\s*(danke|thank you|anbei|attached|unten|siehe|hier)\b", txt):
            a_score += 2

        label = "question" if q_score > a_score else "answer"
        labeled_rev.append({"label": label, "text": txt})

    return list(reversed(labeled_rev))


def render_html(source_name: str, subject: str, labeled_blocks: list[dict], stats: dict) -> str:
    legend = "Sensitive removed: Names, Emails, Phones, URLs/Domains, IBAN, References/IDs, Money"
    meta = {
        "source": source_name,
        "generated": now_ts(),
        "subject": subject,
        "redaction_stats": stats,
    }

    parts = []
    parts.append("<html><head><meta charset='utf-8'><title>Sanitized Mail</title></head>")
    parts.append("<body style='font-family:Segoe UI,Arial; font-size:13px; line-height:1.35; padding:16px;'>")
    parts.append(f"<div><b>Source:</b> {escape(source_name)}<br>")
    parts.append(f"<b>Generated:</b> {escape(meta['generated'])}<br>")
    parts.append(f"<b>Legend:</b> {escape(legend)}<br>")
    parts.append(f"<b>Subject:</b> {escape(subject)}<br></div>")
    parts.append("<hr>")
    parts.append("<div style='color:#666; font-size:12px;'><b>Metadata (json):</b>")
    parts.append(f"<pre style='white-space:pre-wrap'>{escape(json.dumps(meta, ensure_ascii=False))}</pre></div>")
    parts.append("<hr>")

    if not labeled_blocks:
        parts.append("<p><i>(no usable body text extracted)</i></p>")
    else:
        parts.append("<h3 style='margin:0 0 8px 0;'>Body</h3>")
        for blk in labeled_blocks:
            badge = "QUESTION" if blk["label"] == "question" else "ANSWER"
            parts.append(
                "<div style='margin:10px 0; padding:10px; border:1px solid #ddd; border-radius:8px;'>"
                f"<div style='font-weight:600; margin-bottom:6px;'>{escape(badge)}</div>"
                f"<div>{escape(blk['text']).replace(chr(10), '<br>')}</div>"
                "</div>"
            )

    parts.append("</body></html>")
    return "".join(parts)


def ensure_dirs():
    out_base = Path(OUT_DIR)
    out_base.mkdir(parents=True, exist_ok=True)
    out_html = out_base / OUT_SUBFOLDER
    out_html.mkdir(parents=True, exist_ok=True)
    return out_html


def walk_msg_files(root: Path) -> list[Path]:
    return [p for p in root.rglob("*.msg") if p.is_file()]


def main():
    msg_root = Path(MSG_DIR)
    if not msg_root.exists():
        raise SystemExit(f"MSG_DIR not found: {MSG_DIR}")

    out_html_dir = ensure_dirs()
    errors_log = Path(OUT_DIR) / "errors.log"
    summary_json = Path(OUT_DIR) / "summary.json"

    msg_files = walk_msg_files(msg_root)
    if not msg_files:
        raise SystemExit("No .msg files found in MSG_DIR (recursively).")

    # reset logs each run
    errors_log.write_text("", encoding="utf-8")

    jsonl_path = Path(OUT_DIR) / JSONL_NAME
    if WRITE_JSONL:
        jsonl_path.write_text("", encoding="utf-8")

    processed = 0
    failed = 0
    summaries = []

    # Try import once (faster + clearer errors)
    try:
        import extract_msg  # noqa: F401
    except Exception as e:
        raise SystemExit(f"extract-msg import failed. Install/upgrade with: py -m pip install -U extract-msg\nError: {e}")

    for p in sorted(msg_files):
        try:
            parsed = parse_msg(p)
            subject_raw = parsed.get("subject") or p.stem
            body_raw = pick_best_body(parsed)

            subject_clean, s_stats = redact_text(strip_headers_and_signatures(subject_raw))
            body_clean, b_stats = redact_text(strip_headers_and_signatures(body_raw))

            stats = {k: int(s_stats.get(k, 0)) + int(b_stats.get(k, 0)) for k in set(s_stats) | set(b_stats)}

            blocks = split_chain_blocks(body_clean)
            blocks = [b for b in blocks if len(b.strip()) >= 20]
            labeled = label_blocks_heuristic(blocks)

            out_name = safe_out_name(p)
            out_path = out_html_dir / out_name
            out_path.write_text(render_html(p.name, subject_clean, labeled, stats), encoding="utf-8")

            processed += 1
            summaries.append({
                "file": str(p),
                "out": str(out_path),
                "subject": subject_clean,
                "blocks": len(labeled),
                "stats": stats,
            })

            if WRITE_JSONL:
                record = {
                    "source_file": p.name,
                    "subject": subject_clean,
                    "segments": labeled,
                }
                with jsonl_path.open("a", encoding="utf-8") as f:
                    f.write(json.dumps(record, ensure_ascii=False) + "\n")

        except Exception as e:
            failed += 1
            with errors_log.open("a", encoding="utf-8") as f:
                f.write(f"[{now_ts()}] ERROR: {p.name} -> {repr(e)}\n")

    summary = {
        "generated": now_ts(),
        "msg_dir": MSG_DIR,
        "out_dir": str(out_html_dir),
        "processed": processed,
        "failed": failed,
        "total": len(msg_files),
    }
    summary_json.write_text(json.dumps({"summary": summary, "files": summaries}, ensure_ascii=False, indent=2), encoding="utf-8")
    print("Done.")
    print(json.dumps(summary, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()
